{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "96cceb18-3c3d-49e6-8e3d-26c79570f697",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "# Einführung in Python für die Computational Social Science (CSS)\n",
    "## Session 03 - Grundlagen II + pandas I\n",
    "\n",
    "\n",
    "\n",
    "## Jonas Volle\n",
    "Wissenschaftlicher Mitarbeiter  \n",
    "Chair of Methodology and Empirical Social Research  \n",
    "Otto-von-Guericke-Universität  \n",
    "\n",
    "[jonas.volle@ovgu.de](mailto:jonas.volle@ovgu.de)\n",
    "\n",
    "**Sprechstunde**: individuell nach vorheriger Anmeldung per [Mail](mailto:jonas.volle@ovgu.de)\n",
    "\n",
    "Donnerstag, 16.05.2023"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bee7974-dbec-4873-b9c1-03ae5bbb08de",
   "metadata": {},
   "source": [
    "**Quelle:** Ich orientiere mich für diese Sitzung an den Kapiteln 3 und 6 aus dem Buch:  \n",
    "\n",
    "McLevey, John. 2021. Doing Computational Social Science: A Practical Introduction. 1st ed. Thousand Oaks: SAGE Publications.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f35724eb-2bc7-4473-a286-d561f3ecc4e7",
   "metadata": {},
   "source": [
    "## Inhalt\n",
    "\n",
    "- Datenstrukturen (Lists, Dictionaries)\n",
    "- Funktionen\n",
    "- Datenmanagement mit pandas\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d8c239d-0ffa-40ed-85a0-4052ac62815e",
   "metadata": {},
   "source": [
    "## 1. Datenstrukturen (Lists, Tuples, Dictionaries)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "028e7495-3440-41f3-9f96-418f8513c7a8",
   "metadata": {},
   "source": [
    "### Listen\n",
    "\n",
    "In Python sind Listen geordnete Sammlungen beliebiger Objekte, wie z. B. Strings, Ganzzahlen, Fließkommazahlen oder andere Datenstrukturen - sogar andere Listen. Die Elemente in einer Liste können vom gleichen Typ sein, müssen es aber nicht. Python-Listen sind sehr flexibel. Sie können Informationen verschiedener Art in einer Liste mischen, Sie können der Liste während des laufenden Betriebs Informationen hinzufügen, und Sie können alle in der Liste enthaltenen Informationen entfernen oder ändern. Dies ist in anderen Sprachen nicht immer der Fall. Die einfachste Liste sieht wie folgt aus:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "57ae64d9-a481-44b9-a6cc-1cde6167dfff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_list = []\n",
    "my_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "67a1f3af-811d-4c06-aecd-3a5237d77f7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_list = list()\n",
    "my_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f14600cd-f0a8-40fe-95ee-39923363b511",
   "metadata": {},
   "source": [
    "Alle Listen beginnen und enden mit eckigen Klammern `[]`, und die Elemente werden durch ein Komma getrennt. Im Folgenden definieren wir zwei Listen mit Strings (Megastädte in einer Liste und ihre Länder in einer anderen) und eine Liste mit Zahlen (Einwohnerzahl der Städte im Jahr 2018)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a51c99b0-b37d-482b-adc1-aa66acf88cea",
   "metadata": {},
   "outputs": [],
   "source": [
    "megacities = ['Tokyo','Delhi','Shanghai','Sao Paulo','Mexico City','Cairo','Dhaka','Mumbai','Beijing','Osaka']\n",
    "countries = ['Japan','India','China','Brazil','Mexico','Egypt','Bangladesh','India','China','Japan']\n",
    "pop2018 = [37468000, 28514000, 25582000, 21650000, 21581000, 20076000, 19980000, 19618000, 19578000, 19281000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f9b639f0-b753-4f38-a0cd-6b0759b7657a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Tokyo',\n",
       " 'Delhi',\n",
       " 'Shanghai',\n",
       " 'Sao Paulo',\n",
       " 'Mexico City',\n",
       " 'Cairo',\n",
       " 'Dhaka',\n",
       " 'Mumbai',\n",
       " 'Beijing',\n",
       " 'Osaka']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "megacities"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ebbf008-7e86-436c-ba3e-ba6e19ba5b8f",
   "metadata": {},
   "source": [
    "Jedes Element in einer Liste hat einen Index, der auf seiner Position in der Liste basiert. Indizes sind ganze Zahlen, und wie in den meisten anderen Programmiersprachen beginnt die Indizierung in Python bei 0, was bedeutet, dass der erste Eintrag in einer Liste - oder in allem anderen, was in Python indiziert wird - bei 0 beginnt. In der Liste der Megastädte ist der Index für Tokio 0, Delhi ist 1, Shanghai ist 2, und so weiter.  \n",
    "\n",
    "Wir können den Index verwenden, um ein bestimmtes Element aus einer Liste auszuwählen, indem wir den Namen der Liste und dann die Indexnummer in eckigen Klammern eingeben:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "38dfc0fb-b6ce-43e8-b9c9-387bdb2d67c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Sao Paulo'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "megacities[3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4034fef0-6836-4667-9da2-c6b11614f559",
   "metadata": {},
   "source": [
    "Wir können auch auf einzelne Einträge zugreifen, indem wir vom Ende der Liste aus arbeiten. Dazu verwenden wir ein `-`-Zeichen in den Klammern. Beachten Sie, dass wir, anders als beim Aufwärtszählen von 0, nicht von '-0' abwärts zählen. Während `[2]` das dritte Element angibt, gibt `[-2]` das vorletzte Element an. 'China' aus der `countries` Liste, können wir so auswählen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b7b12934-03c8-4ce0-9f51-793df2eb84b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Japan',\n",
       " 'India',\n",
       " 'China',\n",
       " 'Brazil',\n",
       " 'Mexico',\n",
       " 'Egypt',\n",
       " 'Bangladesh',\n",
       " 'India',\n",
       " 'China',\n",
       " 'Japan']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "countries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ccc7f29a-d1a2-46cc-b029-79eaad517511",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'China'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "countries[8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f039f763-ecc1-438e-ab07-716eb6781964",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'China'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "countries[-2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef93e99d-4fb8-4f95-9ec5-8935b229039b",
   "metadata": {},
   "source": [
    "Wenn wir auf ein einzelnes Element in einer Liste zugreifen, gibt Python das Element in seinem Datentyp zurück. So gibt  `megacities[3]` beispielsweise \"Sao Paulo\" als String zurück, und `pop2018[3]` liefert die Ganzzahl 21650000. Wir können jede beliebige Methode verwenden, die mit diesem bestimmten Datentyp verknüpft ist:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "97f07440-d9b0-4d4c-9483-6fe2582bd7ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64950000"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pop2018[3]*3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c428b718-c7dc-4acd-8918-cd9940e94220",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'SAO PAULO'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "megacities[3].upper()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c51fb4ac-e365-4d0a-8e97-ed116e42cca5",
   "metadata": {},
   "source": [
    "Die Verwendung von eckigen Klammern für den Zugriff auf ein Element in einer Liste (oder einem Tupel, einer Menge oder einem Wörterbuch) wird als Indexierung bezeichnet.  \n",
    "Wenn wir mehrere Elemente auswählen möchten können wir die sclice-Notation verwenden, bei der zwei Indexpositionen durch einen Doppelpunkt getrennt sind:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "38369781-079b-4fb1-92a8-5982b559ba30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Tokyo', 'Delhi', 'Shanghai']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "megacities[0:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bd943fc-474d-479c-a1be-b929626ac09a",
   "metadata": {},
   "source": [
    "Die Verwendung eines Slice zur Indexierung einer Liste gibt das Element an der Position der ersten Ganzzahl sowie jedes Element an jeder Position zwischen der ersten und der zweiten Ganzzahl zurück. Das Element, das durch die zweite ganze Zahl indiziert ist, wird nicht zurückgegeben. Um die letzten drei Einträge unserer Liste abzurufen, würden Sie Folgendes verwenden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "29e9ad2f-1f48-40e4-99f9-adb62d697f47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Japan',\n",
       " 'India',\n",
       " 'China',\n",
       " 'Brazil',\n",
       " 'Mexico',\n",
       " 'Egypt',\n",
       " 'Bangladesh',\n",
       " 'India',\n",
       " 'China',\n",
       " 'Japan']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "countries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "87cd4c09-713e-41a9-b23f-5acf3960fc01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['India', 'China', 'Japan']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "countries[7:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f397bfdc-b0b4-48db-90ab-61af8648f82a",
   "metadata": {},
   "source": [
    "Sie können auch die Slice-Notation mit einer fehlenden ganzen Zahl verwenden, um alle Elemente einer Liste bis zu - oder ab - einer bestimmten Indexposition zurückzugeben. Im Folgenden finden Sie die ersten drei Megastädte,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "92f71a41-a2f9-45c2-bffc-bd05221bec4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Tokyo', 'Delhi', 'Shanghai']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "megacities[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d3d34c4-fc13-4eb5-89ee-8062caab6a5d",
   "metadata": {},
   "source": [
    "und die letzten sieben:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5e5ab31b-4767-470f-8827-b7a61d37f900",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Sao Paulo', 'Mexico City', 'Cairo', 'Dhaka', 'Mumbai', 'Beijing', 'Osaka']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "megacities[-7:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79dc7dfb-b400-4a83-b1b0-5ace09cde715",
   "metadata": {},
   "source": [
    "### Looping over lists"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "934e25fd-b3d0-4664-8b5f-b6f954d7ca46",
   "metadata": {},
   "source": [
    "Pythons Listen sind iterierbare Objekte, was bedeutet, dass wir über die Elemente der Liste iterieren (oder loopen) können, um Code für jedes einzelne Element auszuführen. Dies wird üblicherweise mit einer *for-Schleife* durchgeführt. Im Folgenden wird die Liste Megastädte durchlaufen und jedes Element ausgedruckt:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "46f0bd7f-4670-45ab-bdbd-0542f4f83c2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokyo\n",
      "Delhi\n",
      "Shanghai\n",
      "Sao Paulo\n",
      "Mexico City\n",
      "Cairo\n",
      "Dhaka\n",
      "Mumbai\n",
      "Beijing\n",
      "Osaka\n"
     ]
    }
   ],
   "source": [
    "for city in megacities: \n",
    "    print(city)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "331407cf-9a9b-4421-a0f9-259884f4a19c",
   "metadata": {},
   "source": [
    "Dieser Code erstellt eine temporäre Variable namens city, die auf das aktuelle Element der Megastädte verweist, über die iteriert wird. Der Name für diese Variable sollte etwas Beschreibendes sein, das Ihnen etwas über die Elemente der Liste verrät."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd3415f0-7131-4776-84bc-fbc912e91e20",
   "metadata": {},
   "source": [
    "### Ändern von Listen"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6db095a2-4aad-4203-ba98-a8f94fc232fb",
   "metadata": {},
   "source": [
    "Listen können auf verschiedene Weise geändert werden. Wir können die Elemente in der Liste wie andere Werte ändern, z. B. den String \"Mexico City\" in \"Ciudad de México\", indem wir den Index des Werts verwenden:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5feed013-f290-4bb6-af95-33aaa2cd09cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Tokyo', 'Delhi', 'Shanghai', 'Sao Paulo', 'Ciudad de México', 'Cairo', 'Dhaka', 'Mumbai', 'Beijing', 'Osaka']\n"
     ]
    }
   ],
   "source": [
    "megacities[4] = 'Ciudad de México' \n",
    "print(megacities)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52c5c5cc-c867-4bc8-956c-294136e146f3",
   "metadata": {},
   "source": [
    "Wir wollen oft Elemente einer Liste hinzufügen oder entfernen. Fügen wir Karachi zu unseren drei Listen hinzu, indem wir die Methode `.append()` verwenden:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "334a3115-f567-4315-8c51-2ef0a160e5cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "megacities.append('Karachi') \n",
    "countries.append('Pakistan')\n",
    "pop2018.append(16000000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c04c72e2-2486-4666-a7a9-7b22226fe446",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Tokyo',\n",
       " 'Delhi',\n",
       " 'Shanghai',\n",
       " 'Sao Paulo',\n",
       " 'Ciudad de México',\n",
       " 'Cairo',\n",
       " 'Dhaka',\n",
       " 'Mumbai',\n",
       " 'Beijing',\n",
       " 'Osaka',\n",
       " 'Karachi']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "megacities"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0211bd03-dedd-456f-b4dd-2424662655b2",
   "metadata": {},
   "source": [
    "Sie werden `.append()` häufig verwenden. Es ist ein sehr bequemer Weg, um eine Liste dynamisch zu erstellen und zu verändern. Lassen Sie uns eine neue Liste erstellen, die einen formatierten String für jede Stadt enthalten soll."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d75965f7-54ac-4729-9cfd-b670bdd38393",
   "metadata": {},
   "outputs": [],
   "source": [
    "city_strings = [] \n",
    "\n",
    "for city in megacities:\n",
    "    city_string_tmp = f\"What's the population of {city}?\" \n",
    "    city_strings.append(city_string_tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3acbb994-dce2-4ce0-9e8c-581516b8518a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"What's the population of Tokyo?\",\n",
       " \"What's the population of Delhi?\",\n",
       " \"What's the population of Shanghai?\",\n",
       " \"What's the population of Sao Paulo?\",\n",
       " \"What's the population of Ciudad de México?\",\n",
       " \"What's the population of Cairo?\",\n",
       " \"What's the population of Dhaka?\",\n",
       " \"What's the population of Mumbai?\",\n",
       " \"What's the population of Beijing?\",\n",
       " \"What's the population of Osaka?\",\n",
       " \"What's the population of Karachi?\"]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "city_strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "930ae13e-5100-45a8-a189-0324bf4a16fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What's the population of Tokyo?\n",
      "What's the population of Delhi?\n",
      "What's the population of Shanghai?\n",
      "What's the population of Sao Paulo?\n",
      "What's the population of Ciudad de México?\n",
      "What's the population of Cairo?\n",
      "What's the population of Dhaka?\n",
      "What's the population of Mumbai?\n",
      "What's the population of Beijing?\n",
      "What's the population of Osaka?\n",
      "What's the population of Karachi?\n"
     ]
    }
   ],
   "source": [
    "for city_string in city_strings: \n",
    "    print(city_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48f81709-27b7-4621-ad0c-0c6012945d06",
   "metadata": {},
   "source": [
    "Das Entfernen von items ist ebenso einfach. Es gibt mehrere Möglichkeiten, aber `.remove()` ist eine der gängigsten:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4af1447b-6d76-4f79-b12f-2d0d5201eed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "megacities.remove('Karachi') \n",
    "countries.remove('Pakistan') \n",
    "pop2018.remove(16000000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6f1812c1-3423-4981-8359-73e24c100cba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Tokyo',\n",
       " 'Delhi',\n",
       " 'Shanghai',\n",
       " 'Sao Paulo',\n",
       " 'Ciudad de México',\n",
       " 'Cairo',\n",
       " 'Dhaka',\n",
       " 'Mumbai',\n",
       " 'Beijing',\n",
       " 'Osaka']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "megacities"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdf56d94-ed29-4bfb-b981-4901236226c1",
   "metadata": {},
   "source": [
    "Manchmal möchte man die Ordnung einer Liste ändern. Normalerweise wird die Liste auf irgendeine Weise sortiert (z. B. alphabetisch, absteigend). Im Folgenden erstellen wir eine Kopie von Megastädte und sortieren sie alphabetisch. Da wir das Originalobjekt nicht verändern wollen, erstellen wir explizit eine neue Kopie mit der Methode `.copy()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "988e56f9-b2a7-4c75-ae96-bae479e287bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Beijing', 'Cairo', 'Ciudad de México', 'Delhi', 'Dhaka', 'Mumbai', 'Osaka', 'Sao Paulo', 'Shanghai', 'Tokyo']\n"
     ]
    }
   ],
   "source": [
    "megacities_copy = megacities.copy() \n",
    "megacities_copy.sort() \n",
    "print(megacities_copy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e85e796-dba5-49b9-801f-8ffc64010dc5",
   "metadata": {},
   "source": [
    "Beachten Sie, dass wir beim Aufruf von `.sort()`  kein `=` verwenden. Diese Methode wird 'in-place' ausgeführt, d.h. sie verändert das Objekt, das sie aufruft. Die Zuweisung von `megacities_copy.sort()` gibt tatsächlich `None` zurück, ein spezieller Wert in Python."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f65b7e25-a4f7-426d-b79f-1b8e3c9de04d",
   "metadata": {},
   "source": [
    "Bei Anwendung auf eine Liste von Zahlen sortiert `.sort()` die Liste von der kleinsten zur größten Zahl um:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1590b5ed-6da3-4c5b-b8ad-a4bd27b4f600",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19281000, 19578000, 19618000, 19980000, 20076000, 21581000, 21650000, 25582000, 28514000, 37468000]\n"
     ]
    }
   ],
   "source": [
    "pop_copy = pop2018.copy() \n",
    "pop_copy.sort() \n",
    "print(pop_copy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6982092-ddfc-4984-8054-582c8e3aec66",
   "metadata": {},
   "source": [
    "Um eine Liste in umgekehrter alphabetischer Reihenfolge oder von der größten zur kleinsten Zahl zu sortieren, können wir das Argument `reverse=True` in der `.sort()`-Methode verwende."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b16be6d4-715c-4db7-bd76-08e546691fd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[37468000, 28514000, 25582000, 21650000, 21581000, 20076000, 19980000, 19618000, 19578000, 19281000]\n"
     ]
    }
   ],
   "source": [
    "pop_copy.sort(reverse=True) \n",
    "print(pop_copy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "3601de19-f6fc-4279-bcbf-1ac58a194b10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Tokyo', 'Shanghai', 'Sao Paulo', 'Osaka', 'Mumbai', 'Dhaka', 'Delhi', 'Ciudad de México', 'Cairo', 'Beijing']\n"
     ]
    }
   ],
   "source": [
    "megacities_copy.sort(reverse=True) \n",
    "print(megacities_copy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c35d8b4b-8d07-4542-bc3b-aa64a7db3944",
   "metadata": {},
   "source": [
    "### Zipping and unzipping lists"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b3b3a61-2d55-4558-aa71-d142589b5656",
   "metadata": {},
   "source": [
    "Wenn Sie Daten haben, die über mehrere Listen verteilt sind, kann es nützlich sein, diese Listen zusammenzuzippen, so dass alle Elemente mit einem Index von 0 miteinander verbunden sind, alle Elemente mit einem Index von 1 und so weiter. Der einfachste Weg, dies zu tun, ist die Verwendung der Funktion `zip()`, die im folgenden Codeblock dargestellt ist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "33e61455-e4f7-4a80-b212-2f47f30b6a90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Tokyo', 'Japan', 37468000)\n",
      "('Delhi', 'India', 28514000)\n",
      "('Shanghai', 'China', 25582000)\n",
      "('Sao Paulo', 'Brazil', 21650000)\n",
      "('Ciudad de México', 'Mexico', 21581000)\n",
      "('Cairo', 'Egypt', 20076000)\n",
      "('Dhaka', 'Bangladesh', 19980000)\n",
      "('Mumbai', 'India', 19618000)\n",
      "('Beijing', 'China', 19578000)\n",
      "('Osaka', 'Japan', 19281000)\n"
     ]
    }
   ],
   "source": [
    "for paired in zip(megacities,countries, pop2018): \n",
    "    print(paired)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dacaf23c-66d5-4a9f-80fd-c21dae87c761",
   "metadata": {},
   "source": [
    "Das eigentliche Objekt, das die Funktion `zip()` zurückgibt, ist ein \"zip-Objekt\", in dem unsere Daten als eine Reihe von Tupeln gespeichert sind. Wir können diese gezippten Tupel mit der Funktion `list()` in eine Liste von Tupeln umwandeln:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7a156c0a-403c-4ff0-9c4d-294cacec0a06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Tokyo', 'Japan', 37468000), ('Delhi', 'India', 28514000), ('Shanghai', 'China', 25582000), ('Sao Paulo', 'Brazil', 21650000), ('Ciudad de México', 'Mexico', 21581000), ('Cairo', 'Egypt', 20076000), ('Dhaka', 'Bangladesh', 19980000), ('Mumbai', 'India', 19618000), ('Beijing', 'China', 19578000), ('Osaka', 'Japan', 19281000)]\n"
     ]
    }
   ],
   "source": [
    "zipped_list = list(zip(megacities,countries,pop2018)) \n",
    "print(zipped_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4ac2dc9-1c98-44cf-9cc2-3c8405ec67c5",
   "metadata": {},
   "source": [
    "Es ist auch möglich, eine gezippte Liste mit Hilfe des `*`-Operators und der Mehrfachzuweisung (auch \"unpacking\" genannt) zu entpacken, wodurch wir mehreren Variablen in einer einzigen Zeile mehrere Werte zuweisen können. Der folgende Code gibt zum Beispiel drei Objekte zurück. Wir weisen jedes einer Variablen auf der linken Seite des `=`-Zeichens zu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "8166a2d6-4e17-43ad-8236-b742edf2381d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Tokyo', 'Delhi', 'Shanghai', 'Sao Paulo', 'Ciudad de México', 'Cairo', 'Dhaka', 'Mumbai', 'Beijing', 'Osaka')\n",
      "('Japan', 'India', 'China', 'Brazil', 'Mexico', 'Egypt', 'Bangladesh', 'India', 'China', 'Japan')\n",
      "(37468000, 28514000, 25582000, 21650000, 21581000, 20076000, 19980000, 19618000, 19578000, 19281000)\n"
     ]
    }
   ],
   "source": [
    "city_unzip, country_unzip, pop_unzip = zip(*zipped_list) \n",
    "print(city_unzip) \n",
    "print(country_unzip) \n",
    "print(pop_unzip)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cb0af39-922a-4b6e-83b3-c3192ba43bec",
   "metadata": {},
   "source": [
    "### List comprehensions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f55f0c4a-90eb-4db9-a094-12cb681e0f11",
   "metadata": {},
   "source": [
    "Zuvor haben wir eine leere Liste erstellt und sie mit `.append()` in einer for-Schleife aufgefüllt. Wir können auch die *list comprehension* verwenden, welche das gleiche Ergebnis in einer einzigen Codezeile liefern kann. Zur Veranschaulichung wollen wir versuchen, die Anzahl der Zeichen im Namen jedes Landes in der Länderliste mit einer for-Schleife und anschließend mit einer *list comprehension* zu zählen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d3e90695-7899-4ad1-88db-6ecf5b70f966",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5, 5, 5, 6, 6, 5, 10, 5, 5, 5]\n"
     ]
    }
   ],
   "source": [
    "len_country_name = [] \n",
    "\n",
    "for country in countries: \n",
    "    n_chars_tmp = len(country) \n",
    "    len_country_name.append(n_chars_tmp) \n",
    "\n",
    "print(len_country_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "2aca759f-25ff-41ef-9a3e-e34ed67daddf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5, 5, 5, 6, 6, 5, 10, 5, 5, 5]\n"
     ]
    }
   ],
   "source": [
    "len_country_name = [len(country) for country in countries] \n",
    "\n",
    "print(len_country_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af6dd6e7-6994-426a-b30b-5bcb31a19dac",
   "metadata": {},
   "source": [
    "*List comprehension* können anfangs etwas ungewohnt sein, aber mit etwas Übung werden sie einfacher. Das Wichtigste, was Sie sich merken müssen, ist, dass *list comprehensions* immer folgendes enthalten:  \n",
    "\n",
    "1. den Ausdruck selbst, der auf jedes Element der ursprünglichen Liste angewandt wird (in diesem Fall `len()`), \n",
    "2. den Namen der temporären Variable der auf das iterierbare Objekt verweist (in diesem Fall `country`) \n",
    "3. das iterierbare Objekt (in diesem Fall die Liste `countries`)\n",
    "\n",
    "Häufig möchten wir unseren for-Schleifen und `list comprehension` eine Bedingung hinzufügen. Erstellen wir eine neue Liste von Städten mit mehr als 20.500.000 Einwohnern mit Hilfe der Funktion `zip()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "3c3e12a6-2ad5-4af3-a052-e5563dafafde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['Tokyo', 37468000], ['Delhi', 28514000], ['Shanghai', 25582000], ['Sao Paulo', 21650000], ['Ciudad de México', 21581000]]\n"
     ]
    }
   ],
   "source": [
    "biggest = [[city, population] for city, population in zip(megacities, pop2018) if population > 20500000] \n",
    "\n",
    "print(biggest)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f1bf69e-38f8-47df-9404-69c92d2dbc38",
   "metadata": {},
   "source": [
    "Das Ergebnis - biggest - ist eine Liste von Listen. Wir können mit verschachtelten Datenstrukturen wie dieser arbeiten, indem wir die gleichen Werkzeuge verwenden, die wir für flache Datenstrukturen benutzen. Zum Beispiel,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ad3c4412-af1c-4eff-ba8c-b9ee18327528",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The population of Tokyo in 2018 was 37468000\n",
      "The population of Delhi in 2018 was 28514000\n",
      "The population of Shanghai in 2018 was 25582000\n",
      "The population of Sao Paulo in 2018 was 21650000\n",
      "The population of Ciudad de México in 2018 was 21581000\n"
     ]
    }
   ],
   "source": [
    "for city in biggest: \n",
    "    print(f'The population of {city[0]} in 2018 was {city[1]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9cd945d-1e3b-4a38-aa1b-f2e50e832da6",
   "metadata": {},
   "source": [
    "Wann sollten Sie eine for-Schleife und wann eine *list comprehension* verwenden?  \n",
    "\n",
    "In vielen Fällen ist das eine Frage der persönlichen Vorliebe. *List Comprehensions* sind etwas übersichtlicher aber mit etwas Python-Erfahrung dennoch lesbar. Sie werden jedoch sehr schnell unleserlich, wenn Sie viele Operationen für jedes Element durchführen müssen oder wenn Sie auch nur eine leicht komplexe bedingte Logik/Bedingung haben. In diesen Fällen sollten Sie auf jeden Fall *list comprehensions* vermeiden. Wir wollen immer sicherstellen, dass unser Code so lesbar wie möglich ist."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb60c003-e88e-48a1-ab95-ca9f2f16a281",
   "metadata": {},
   "source": [
    "<div class='alert alert-block alert-success'>\n",
    "\n",
    "### Aufgabe 1\n",
    "\n",
    "--> session_03_excercise_1.ipynb\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04e1a429-65b7-4e84-8109-5dc70cffd113",
   "metadata": {},
   "source": [
    "### Listen kopieren"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "4f92c14b-e550-4069-9f66-b6c1537d71e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Japan', 'India', 'China', 'Brazil', 'Mexico', 'Egypt', 'Bangladesh', 'India', 'China', 'Japan']\n"
     ]
    }
   ],
   "source": [
    "countries_copy = countries \n",
    "print(countries_copy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b6462e7e-dd12-4e71-914a-ee2bea7b3d66",
   "metadata": {},
   "outputs": [],
   "source": [
    "countries_copy.append('USA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "18cfa2d9-daa3-49f5-9f5a-beaaf8cb3452",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Japan',\n",
       " 'India',\n",
       " 'China',\n",
       " 'Brazil',\n",
       " 'Mexico',\n",
       " 'Egypt',\n",
       " 'Bangladesh',\n",
       " 'India',\n",
       " 'China',\n",
       " 'Japan',\n",
       " 'USA']"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "countries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "73412e40-fdcd-4061-908e-77f32f71d882",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Japan', 'India', 'China', 'Brazil', 'Mexico', 'Egypt', 'Bangladesh', 'India', 'China', 'Japan', 'USA']\n"
     ]
    }
   ],
   "source": [
    "countries_copy_copy = countries.copy()\n",
    "print(countries_copy_copy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "94622dfb-db53-4e5d-b85c-ee5d57e56d87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Japan',\n",
       " 'India',\n",
       " 'China',\n",
       " 'Brazil',\n",
       " 'Mexico',\n",
       " 'Egypt',\n",
       " 'Bangladesh',\n",
       " 'India',\n",
       " 'China',\n",
       " 'Japan',\n",
       " 'USA',\n",
       " 'France']"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "countries_copy_copy.append('France')\n",
    "countries_copy_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "47f28e6a-45c9-4f9c-9de9-ba0ee52ee874",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Japan',\n",
       " 'India',\n",
       " 'China',\n",
       " 'Brazil',\n",
       " 'Mexico',\n",
       " 'Egypt',\n",
       " 'Bangladesh',\n",
       " 'India',\n",
       " 'China',\n",
       " 'Japan',\n",
       " 'USA']"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "countries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b62682f6-b765-4071-9431-1296c3b72d38",
   "metadata": {},
   "source": [
    "Dieser Code scheint eine Kopie von Ländern zu erzeugen, aber das ist eine Illusion. Wenn wir eine Liste mit dem Operator `=` kopieren, erstellen wir **kein** neues Objekt. Stattdessen haben wir einen neuen Variablennamen erstellt, der auf das ursprüngliche Objekt im Speicher verweist. Wir haben ein Objekt mit zwei Namen, anstatt zwei verschiedene Objekte. Alle Änderungen, die mit `countries_copy` vorgenommen werden, ändern das gleiche Objekt im Speicher, das durch `countries` beschrieben wird. Wenn wir Karachi an `countries_copy` anhängen und `countries` ausdrucken, würden wir Karachi sehen, und umgekehrt. Wenn wir die ursprüngliche Liste beibehalten und Änderungen an der zweiten vornehmen wollen, ist dies nicht möglich. Stattdessen können wir die Methode `.copy()` verwenden, um eine flache Kopie der ursprünglichen Liste zu erstellen, oder `.deepcopy()`, um eine tiefe Kopie zu erstellen. Um den Unterschied zu verstehen, vergleichen Sie eine flache Liste (z. B. `[1, 2, 3]`) mit einer Liste von Listen (z. B. `[[1, 2, 3], [4, 5, 6]]`). Die Liste der Listen ist verschachtelt; sie ist tiefer als die flache Liste. Wenn wir eine flache Kopie (d. h. .copy()) der flachen Liste erstellen, erzeugt Python ein neues Objekt, das vom Original unabhängig ist. Wenn wir jedoch eine flache Kopie der verschachtelten Listen von Listen erstellen, erzeugt Python nur ein neues Objekt für die äußere Liste; es ist nur eine Ebene tief. Die Inhalte der inneren Listen `[1, 2, 3]` und `[4, 5, 6]` wurden nicht kopiert, sie sind nur Verweise auf die ursprünglichen Listen. Mit anderen Worten: Die äußeren Listen (Länge 2) sind unabhängig voneinander, aber die inneren Listen (Länge 3) sind Verweise auf dasselbe Objekt im Speicher. Wenn wir mit verschachtelten Datenstrukturen arbeiten, wie z. B. Listen von Listen, müssen wir `.deepcopy()` verwenden, wenn wir ein neues Objekt erstellen wollen, das völlig unabhängig vom Original ist."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1932cbd1-6ca8-4f43-a301-5d51fb98f77d",
   "metadata": {},
   "source": [
    "### not in or in?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69310c50-6fe0-44b4-aaa0-aa3bf337219c",
   "metadata": {},
   "source": [
    "Listen, die im Forschungskontext verwendet werden, sind in der Regel viel größer als die Beispiele hier. Sie können Tausende oder sogar Millionen von Einträgen enthalten. Um herauszufinden, ob eine Liste einen bestimmten Wert enthält oder nicht, können wir, anstatt eine gedruckte Liste manuell zu durchsuchen, die Operatoren in und not in verwenden, die True oder False auswerten:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "e370bfde-7e74-4954-9ccb-26bbe08f02c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'Mexico' in countries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "51ae0d61-416d-4420-810b-3cf285f7157f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'Mexico' not in countries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb466e27-9ae3-4c7c-8ae9-0876b0b53e54",
   "metadata": {},
   "source": [
    "Diese Operatoren können bei der Verwendung von Bedingungen sehr nützlich sein."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "f6bbf3d9-32f5-4e73-b474-c3d55e1c2a3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Toronto was not one of the 10 largest cities in the world in 2018.\n"
     ]
    }
   ],
   "source": [
    "to_check = 'Toronto' \n",
    "if to_check in megacities: \n",
    "    print(f'{to_check} was one of the 10 largest cities in the world in 2018.') \n",
    "else: \n",
    "    print(f'{to_check} was not one of the 10 largest cities in the world in 2018.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc20ce3c-f85c-4547-b0ca-891e9d96f597",
   "metadata": {},
   "source": [
    "### Using enumerate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "709be525-bade-4d20-8e59-1f874ffcb127",
   "metadata": {},
   "source": [
    "In manchen Fällen möchten wir gleichzeitig auf das Element und seine Indexposition in einer Liste zugreifen. Dies können wir mit der Funktion `enumerate()` erreichen. Erinnern Sie sich an die drei Listen aus dem Megacity-Beispiel. Die Informationen über jede Megastadt sind auf drei Listen verteilt, aber die Indizes werden von diesen Listen gemeinsam genutzt. Im Folgenden zählen wir die Megastädte auf, indem wir eine temporäre Variable für die Indexposition (i) und jedes Element (Stadt) erstellen und darüber iterieren. Wir verwenden diese Werte, um den Namen der Stadt zu drucken, und greifen dann über die Indexposition auf Informationen über Land und Stadtbevölkerung zu. Dies funktioniert natürlich nur, weil die Elemente in der Liste geordnet sind und in jeder Liste gemeinsam genutzt werden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "09b32b30-4498-4569-b19b-25805834e7a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokyo, Japan, has 37468000 residents.\n",
      "Delhi, India, has 28514000 residents.\n",
      "Shanghai, China, has 25582000 residents.\n",
      "Sao Paulo, Brazil, has 21650000 residents.\n",
      "Ciudad de México, Mexico, has 21581000 residents.\n",
      "Cairo, Egypt, has 20076000 residents.\n",
      "Dhaka, Bangladesh, has 19980000 residents.\n",
      "Mumbai, India, has 19618000 residents.\n",
      "Beijing, China, has 19578000 residents.\n",
      "Osaka, Japan, has 19281000 residents.\n"
     ]
    }
   ],
   "source": [
    "for i, city in enumerate(megacities): \n",
    "    print(f'{city}, {countries[i]}, has {str(pop2018[i])} residents.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bace5c79-ee87-41cb-94cd-8a64f0057255",
   "metadata": {},
   "source": [
    "Wie bereits erwähnt, können wir beliebig viele Zeilen in den eingerückten Codeblock einer for-Schleife einfügen, wodurch unnötige Iterationen vermieden werden können. Wenn Sie viele Operationen mit Elementen in einer Liste von Tupeln durchführen müssen, ist es besser, die Datenstruktur einmal zu durchlaufen und alle erforderlichen Operationen durchzuführen, als die Liste mehrmals zu durchlaufen und jedes Mal nur eine kleine Anzahl von Operationen auszuführen. Je nachdem, was Sie erreichen wollen, möchten Sie vielleicht auch die temporären Objekte in Ihrer for-Schleife iterieren. Python erlaubt dies! Innerhalb des eingerückten Codeblocks Ihrer for-Schleife können Sie eine weitere for-Schleife einfügen (und eine weitere innerhalb dieser Schleife, und so weiter)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f52b4441-8778-4155-9aa7-ccd6ff5d5d0f",
   "metadata": {},
   "source": [
    "### Tuples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fa285c6-076a-4ccd-aae7-20f31fc71cdb",
   "metadata": {},
   "source": [
    "In Python ist jedes Objekt entweder veränderlich oder unveränderlich. Wir haben gerade gezeigt, dass Listen in vielerlei Hinsicht veränderbar sind: Hinzufügen und Entfernen von Einträgen, Sortieren und so weiter. Jeder Datentyp in Python, bei dem man etwas an seiner Zusammensetzung ändern kann (Anzahl der Einträge, Werte der Einträge), ist veränderbar. Datentypen, die nach ihrer Instanziierung keine Änderungen zulassen, sind unveränderlich.    \n",
    "\n",
    "Ein Tupel ist eine geordnete, unveränderliche series von Objekten. Man kann sich Tupel als eine besondere Art von Liste vorstellen, die nach der Erstellung nicht mehr geändert werden kann. Syntaktisch gesehen werden die Werte in einem Tupel in `()` und nicht in `[]` gespeichert. Ein leeres Tupel kann auf ähnliche Weise wie eine Liste erzeugt werden:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "9f3dbacc-ae9b-4b60-8c87-7383653d4bf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_empty_tuple_1 = () \n",
    "my_empty_tuple_2 = tuple()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "2d1b216e-8cdc-4e02-bb53-3d11d16012c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "a_useful_tuple = (2, 7, 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2901525-492c-48cc-ac13-5784265d71e2",
   "metadata": {},
   "source": [
    "Mit den Funktionen `tuple()` und `list()` können wir leicht zwischen Tupeln und Listen konvertieren:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "34247671-6deb-4a04-a311-17aaaebf76ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "print(type(countries)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "05d52192-8302-4049-98f6-d59ce30afc12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'tuple'>\n"
     ]
    }
   ],
   "source": [
    "countries_tuple = tuple(countries) \n",
    "print(type(countries_tuple))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a81e9771-707a-4faa-a8ea-199f87367a27",
   "metadata": {},
   "source": [
    "Es gibt viele Verwendungszwecke für Tupel: Wenn Sie unbedingt sicherstellen müssen, dass die Reihenfolge einer series von Objekten erhalten bleibt, verwenden Sie ein Tupel, um dies zu garantieren."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "f73f76f3-24b1-49c9-ba36-c2c026e3bd6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Bangladesh',\n",
       " 'Brazil',\n",
       " 'China',\n",
       " 'China',\n",
       " 'Egypt',\n",
       " 'India',\n",
       " 'India',\n",
       " 'Japan',\n",
       " 'Japan',\n",
       " 'Mexico',\n",
       " 'USA']"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "countries_sorted = countries.copy() \n",
    "countries_sorted.sort() \n",
    "countries_sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "0c0529bc-8f9c-4d24-bfb3-8874dc5ee11d",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'tuple' object has no attribute 'sort'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[61], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mcountries_tuple\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msort\u001b[49m()\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'tuple' object has no attribute 'sort'"
     ]
    }
   ],
   "source": [
    "countries_tuple.sort()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "574c7526-199c-49b9-adf6-fa7802e946e9",
   "metadata": {},
   "source": [
    "### Dictionaries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b8e93fd-db7a-4de3-9c4b-18b42b85f1e5",
   "metadata": {},
   "source": [
    "Eine weitere Python-Datenstruktur, die Sie häufig sehen und verwenden werden, ist das Wörterbuch. Im Gegensatz zu Listen sind Wörterbücher dazu gedacht, zusammengehörige Informationen miteinander zu verbinden. Wörterbücher bieten einen flexiblen Ansatz für die Speicherung von Schlüssel-Wert-Paaren. Jeder Schlüssel muss ein unveränderliches Python-Objekt sein, z. B. eine ganze Zahl, ein Float, ein String oder ein Tupel, und es darf keine doppelten Schlüssel geben. Werte können jede Art von Objekt sein. Wir können auf Werte zugreifen, indem wir den entsprechenden Schlüssel angeben."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5100dcd5-59b3-4b28-95a1-26d6a34b3eae",
   "metadata": {},
   "source": [
    "Während bei Listen eckige Klammern `[]` und bei Tupeln runde Klammern `()` verwendet werden, werden in Pythons Dictionaries Schlüssel:Wert-Paare in geschweifte Klammern `{}` verpackt, wobei die Schlüssel und Werte durch einen Doppelpunkt `:` und jedes Paar durch ein `,` getrennt werden. Zum Beispiel,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "db222e25-07b4-4dd5-b5d9-9c2d183e845c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'country': 'Japan', 'pop2018': 37468000}\n"
     ]
    }
   ],
   "source": [
    "tokyo = { \n",
    "    'country' : 'Japan', \n",
    "    'pop2018': 37468000 }\n",
    "print(tokyo)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad9909f7-477e-4b2c-bf1e-55b07f61eddc",
   "metadata": {},
   "source": [
    "Bei der Erstellung eines Wörterbuchs können beliebig viele Schlüssel verwendet werden. Um schnell auf eine Liste aller Schlüssel im Wörterbuch zuzugreifen, können wir die Methode `.keys()` verwenden:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "42ddb91f-e0ec-43b8-a705-efabbf3b2cd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['country', 'pop2018'])\n"
     ]
    }
   ],
   "source": [
    "print(tokyo.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6741534a-a20f-422d-ae58-71887c40671f",
   "metadata": {},
   "source": [
    "Um auf einen bestimmten Wert in einem Wörterbuch zuzugreifen, geben wir den Namen des Wörterbuchobjekts gefolgt vom Namen des Schlüssels, auf dessen Wert wir zugreifen möchten, in eckigen Klammern und Anführungszeichen an. So greifen wir auf die Bevölkerung unseres Wörterbuchs tokyo zu:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "a8cb6d08-5e83-4bd1-a9d2-23d3f7e318d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "37468000"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokyo['pop2018']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ff3ec8a-e215-4489-bc9a-b916b41892bf",
   "metadata": {},
   "source": [
    "Wie Listen können auch Wörterbücher während der Arbeit geändert werden. Wir können ein neues Schlüssel-Wert-Paar zu tokyo hinzufügen - z. B. die Bevölkerungsdichte des Großraums Tokio - und dabei dieselbe Syntax verwenden, die wir für den Verweis auf einen Schlüssel gelernt haben, nur dass wir auch einen Wert zuweisen. Da der Schlüssel, auf den wir verweisen, nicht im Wörterbuch vorhanden ist, weiß Python, dass wir ein neues Schlüssel-Wert-Paar erstellen und nicht ein altes durch einen neuen Wert ersetzen. Wenn wir das Wörterbuch ausdrucken, können wir sehen, dass unser neues Paar hinzugefügt wurde."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "61d04e8a-1224-433b-a6df-a85b164ef74d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'country': 'Japan', 'pop2018': 37468000, 'density': 1178.4}\n"
     ]
    }
   ],
   "source": [
    "tokyo['density'] = 1178.4 \n",
    "print(tokyo)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d919d39f-f167-491a-a441-bdd0bbdca54b",
   "metadata": {},
   "source": [
    "In diesem Fall haben wir mit einem Wörterbuch begonnen, das bereits einige Schlüssel-Wert-Paare enthielt, als wir das Wörterbuch zum ersten Mal definierten. Wir hätten aber auch mit einem leeren Wörterbuch beginnen und es mit Hilfe der soeben erlernten Methode mit Schlüssel-Wert-Paaren füllen können."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "6b999d36-351d-4cbe-ab8a-4ae4d6867be8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'country': 'India', 'pop2018': 28514000, 'density': 11312}\n"
     ]
    }
   ],
   "source": [
    "delhi = {} \n",
    "delhi['country'] = 'India' \n",
    "delhi['pop2018'] = 28514000 \n",
    "delhi['density'] = 11312 \n",
    "\n",
    "print(delhi)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96fab7f1-f1dc-4b97-b73d-6ab92c9e7e8c",
   "metadata": {},
   "source": [
    "### Nested data structures"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6d354d6-069e-4d22-9ef2-dadac61bce38",
   "metadata": {},
   "source": [
    "Listen, Tupel und Wörterbücher können auf verschiedene Weise verschachtelt werden, einschließlich der Verwendung von Wörterbüchern als Elemente in einer Liste, Listen als Elemente in Listen und Listen als Elemente in Wörterbüchern. Andere Arten von verschachtelten Datenstrukturen sind ebenfalls möglich. Die Arbeit mit diesen verschachtelten Strukturen ist sehr einfach. Unabhängig von der Position des Wertes in der verschachtelten Datenstruktur können Sie die für diesen Typ geeigneten Methoden verwenden."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de765e52-329e-4591-b777-f4a1eb0b2c84",
   "metadata": {},
   "source": [
    "Wenn wir ein Wörterbuch haben, das Listen als Werte enthält, können wir auf die Werte zugreifen indem wir zunächst den key und dann den index subscripten."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "39536c95-881f-45fe-b5f0-d2ebd90e7419",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'cities': ['Tokyo', 'Yokohama', 'Osaka', 'Nagoya', 'Sapporo', 'Kobe', 'Kyoto', 'Fukuoka', 'Kawasaki', 'Saitama'], 'populations': [37, 3.7, 8.81, 9.5, 2.7, 1.5, 1.47, 5.6, 1.5, 1.3]}\n"
     ]
    }
   ],
   "source": [
    "japan = {} \n",
    "japan['cities'] = ['Tokyo', 'Yokohama', 'Osaka', 'Nagoya', 'Sapporo', 'Kobe', 'Kyoto', 'Fukuoka', 'Kawasaki', 'Saitama'] \n",
    "japan['populations'] = [37, 3.7, 8.81, 9.5, 2.7, 1.5, 1.47, 5.6, 1.5, 1.3] \n",
    "\n",
    "print(japan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "a446ac78-ed16-4702-b991-a8c05577ffbd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Sapporo'"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "japan['cities'][4]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d25bd432-61c6-44af-8ea6-e891edaa0515",
   "metadata": {},
   "source": [
    "### Lists of dictionaries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6281e8fa-526e-4ce1-9772-3fb3e58f2698",
   "metadata": {},
   "source": [
    "Wir können Wörterbücher auch als Elemente in einer Liste speichern. Zuvor haben wir die Wörterbücher tokyo und delhi erstellt. Beide enthalten die gleichen Schlüssel: Land und Bevölkerung. Das Hinzufügen dieser oder anderer Wörterbücher zu einer Liste ist ganz einfach. Zum Beispiel,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "6aad497a-0d29-439d-95ec-612c5cc99bb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_two = [tokyo, delhi]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "03c07329-5f06-4844-8254-1d0858049c65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'country': 'Japan', 'pop2018': 37468000, 'density': 1178.4}\n",
      "{'country': 'India', 'pop2018': 28514000, 'density': 11312}\n"
     ]
    }
   ],
   "source": [
    "for city in top_two: \n",
    "    print(city)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "dcbe2a96-ca85-41ae-b958-dd15ef90d3cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JAPAN\n",
      "INDIA\n"
     ]
    }
   ],
   "source": [
    "for city in top_two: \n",
    "    print(city['country'].upper())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "9b655537-5fe4-49b6-9a2e-71cc22e50248",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28514000"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_two[1]['pop2018']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70d5ff32-bcf3-4f06-a622-627da022f0da",
   "metadata": {},
   "source": [
    "## 2. Custom functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3f799ea-fd39-4b91-939b-9f942b2cc953",
   "metadata": {},
   "source": [
    "Bisher haben wir einige Funktionen verwendet, die in Python eingebaut sind, z. B. `print()` und `len()`. In diesen und anderen Fällen nehmen die eingebauten Funktionen eine Eingabe entgegen, führen einige Operationen durch und geben dann eine Ausgabe zurück. Wenn wir zum Beispiel der Funktion `len()` einen String übergeben, berechnet sie die Anzahl der Zeichen in diesem String und gibt eine ganze Zahl zurück:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "4019e60e-b586-4df5-8531-22e7d87debc6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seoul = 'Seoul, South Korea' \n",
    "len(seoul)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "720dcbb0-76c2-4219-9deb-0257f5d86db8",
   "metadata": {},
   "source": [
    "Wir hätten die Länge des Strings auch ohne len() berechnen können, zum Beispiel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "90c78628-ae2d-411a-bab2-9096d41cf16f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18\n"
     ]
    }
   ],
   "source": [
    "length = 0 \n",
    "for character in seoul: \n",
    "    length += 1 \n",
    "\n",
    "print(length)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdb5a9f6-27a1-4116-a872-a96a66a56ad3",
   "metadata": {},
   "source": [
    "Beide Teile des Codes berechnen die Länge des in `seoul` gespeicherten Strings, aber die Verwendung von `len()` vermeidet unnötige Arbeit. Wir verwenden Funktionen, um die Vorteile der Abstraktion zu nutzen: Wir wandeln wiederkehrende Aufgaben und Text in komprimierte und leicht zusammenzufassende Werkzeuge um. Moderne Software wie Python basiert auf Jahrzehnten der Abstraktion. Wir programmieren nicht in Binärform, weil wir diesen Prozess abstrahiert haben und zu höheren Sprachen und Funktionen übergegangen sind, die uns Zeit, Platz und Gehirnleistung sparen. Das ist es, was Sie anstreben sollten, wenn Sie Ihre eigenen Funktionen schreiben: Identifizieren Sie kleine Aufgaben oder Probleme, die Sie häufig wiederholen, und schreiben Sie eine gut benannte Funktion, die sie jedes Mal auf die gleiche Weise behandelt, so dass Sie Funktionen kombinieren können, um größere und komplexere Probleme anzugehen."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed52e4f7-272c-4ab7-be50-611c421a6c9a",
   "metadata": {},
   "source": [
    "Stellen Sie sich eine Reihe von Operationen vor, die wir mehrfach anwenden müssen, jedes Mal mit einer anderen Eingabe. Sie beginnen damit, eine dieser Eingaben auszuwählen und den Code zu schreiben, der das gewünschte Endergebnis liefert. Wie geht es nun weiter? Eine Möglichkeit, die ich nicht empfehle, ist das Kopieren und Einfügen des Codes für jeden der Eingänge. Sobald Sie den Code kopiert haben, ändern Sie die Namen der Ein- und Ausgänge so, dass Sie für jeden Eingang den gewünschten Ausgang erhalten."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be4f9455-852a-4767-a05a-df2af308c939",
   "metadata": {},
   "source": [
    "Was passiert, wenn Sie ein Problem im Code entdecken oder ihn verbessern wollen? Sie müssen die relevanten Teile Ihres Codes an mehreren Stellen ändern, und jedes Mal riskieren Sie, etwas zu übersehen oder einen Fehler zu machen. Zu allem Überfluss ist das Skript viel länger als nötig, und die Abfolge der Operationen ist viel schwieriger zu verfolgen und auszuwerten."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cee495f6-c5c5-475f-96b8-a016cb1e25ea",
   "metadata": {},
   "source": [
    "Stattdessen könnten wir unsere eigenen Funktionen schreiben, mit denen wir Teile des Codes strategisch wiederverwenden können. Wenn wir ein Problem entdecken oder etwas ändern wollen, dann müssen wir die Änderung nur an einer Stelle vornehmen. Wenn wir unsere aktualisierte Funktion ausführen, wird sie zuverlässig die gewünschte neue Ausgabe erzeugen. Wir können unsere Funktionen in einem separaten Skript speichern und sie an anderer Stelle importieren, wodurch diese Skripte und Notizbücher übersichtlicher und leichter zu verstehen sind. Und wenn wir gute beschreibende Namen für unsere Funktionen verwenden - etwas, das wir später besprechen werden -, dann können wir von den Details auf niedriger Ebene abstrahieren und uns auf die übergeordneten Details dessen konzentrieren, was wir zu tun versuchen. Das ist immer eine gute Idee, aber es ist besonders hilfreich, wenn nicht sogar unerlässlich, wenn man an großen Projekten arbeitet."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1e98595-ccca-45de-a1f4-5ddbea52eddd",
   "metadata": {},
   "source": [
    "Das Schreiben eigener Funktionen ist also eine sehr leistungsfähige Methode, um unseren Code aufzuteilen und zu organisieren. Es bietet uns viele der gleichen Vorteile wie die Verwendung von eingebauten Funktionen oder Funktionen aus anderen Paketen, aber auch ein paar zusätzliche Vorteile:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9a62fe1-929d-49d3-994b-2dc26bad3557",
   "metadata": {},
   "source": [
    "- Wiederverwendbar - machen Sie keine Arbeit, die bereits erledigt wurde \n",
    "- Abstraktion - abstrahieren Sie Details auf niedriger Ebene, damit Sie sich auf Konzepte und Logik auf höherer Ebene konzentrieren können \n",
    "- Reduzieren Sie das Fehlerpotenzial - wenn Sie einen Fehler finden, brauchen Sie ihn nur an einer Stelle zu beheben \n",
    "- Kürzere und besser lesbare Skripte - viel einfacher zu lesen, zu verstehen und zu bewerten"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3ba9008-10e1-409b-a981-1852f45f045d",
   "metadata": {},
   "source": [
    "### Writing custom functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d6e5752-fe9a-4f7a-b8c8-cd1672525a8b",
   "metadata": {},
   "source": [
    "Um eine Funktion in Python zu definieren, beginnt man mit dem Schlüsselwort `def`, gefolgt vom Namen der Funktion, Klammern mit den Argumenten, die die Funktion annehmen soll, und einem `:`. Der gesamte Code, der ausgeführt wird, wenn die Funktion aufgerufen wird, ist in einem eingerückten Block enthalten. Im Folgenden definieren wir eine Funktion namens `welcome()`, die einen Namen annimmt und eine Begrüßung ausgibt:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "21e973a9-d4fe-4217-a8ea-928530afd71b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hi, Jonas! Good to see you.\n"
     ]
    }
   ],
   "source": [
    "def welcome(name): \n",
    "    print(f'Hi, {name}! Good to see you.') \n",
    "\n",
    "welcome('Jonas')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9280380a-e44f-4215-94e1-9a51a697e542",
   "metadata": {},
   "source": [
    "In diesem Fall gibt die Funktion einen neuen String auf dem Bildschirm aus. Das kann zwar nützlich sein, aber in den meisten Fällen wollen wir etwas mit der Eingabe machen und dann eine andere Ausgabe zurückgeben. Wenn eine Funktion, aus welchem Grund auch immer, keine Ausgabe zurückgibt, gibt sie trotzdem None zurück, wie die Methode .sort()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "c593c2b2-4605-4375-8581-cb683cb76812",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_string(some_string): \n",
    "    cleaned = some_string.strip().lower() \n",
    "    return cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "2b162ecb-9a83-465d-afda-0c928c96380f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hi my name is john mclevey.\n"
     ]
    }
   ],
   "source": [
    "cleaned_str = clean_string('Hi my name is John McLevey.   ') \n",
    "print(cleaned_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4d6790f-8cca-48c8-9ee0-1c1151008f39",
   "metadata": {},
   "source": [
    "<div class='alert alert-block alert-success'>\n",
    "\n",
    "### Aufgabe 2\n",
    "\n",
    "--> session_03_excercise_2.ipynb\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db891724-c23b-4999-a01b-467ee197db64",
   "metadata": {},
   "source": [
    "## 3. Datenmanagement mit Pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d9be2c4-c283-46d7-bb4a-767d3e0bdbc9",
   "metadata": {},
   "source": [
    "Nun verwenden wir Python nicht mehr als allgemeine Programmiersprache, sondern zur Verarbeitung von Daten mit Hilfe spezieller Datenverwaltungs- und -analysepakete. Wir werden uns in erster Linie auf ein Paket namens *Pandas* stützen. Pandas wurde von Wes McKinney für die Analyse von Paneldaten entwickelt (daher der Name). Es verfügt über spezielle Datenstrukturen, Funktionen und Methoden, mit denen Sie die meisten Datenverarbeitungsvorgänge für strukturierte quantitative Daten erledigen können."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "539eee3d-21fa-4442-8b75-81456308b64f",
   "metadata": {},
   "source": [
    "Pandas Dokumentation: https://pandas.pydata.org/docs/reference/index.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c535d97f-5482-483c-b515-07c456c1608a",
   "metadata": {},
   "source": [
    "### Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "a3792c2b-68ac-4f4e-91a4-4a32a1f73707",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d933aa8b-6a55-4d87-a3c3-bf0cde71883d",
   "metadata": {},
   "source": [
    "### Datenimport mit pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca64e403-fd6e-4503-9066-fe71d8315995",
   "metadata": {},
   "source": [
    "Das Pandas-Paket macht es einfach, Daten aus einer externen Datei direkt in ein Dataframe-Objekt zu laden."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35f8f50d-516c-4e0b-9005-f463094fa145",
   "metadata": {},
   "source": [
    "| Datentyp | Reader | Writer |\n",
    "|----------|----------|----------|\n",
    "| CSV    | `read_csv()`   | `to_csv()`   |\n",
    "| JSON    | `read_json()`   | `to_json()`   |\n",
    "| Stata   | `read_stata()`   | `to_stata()`   |\n",
    "| SAS   | `read_sas()`   | NA   |\n",
    "| SPSS   | `read_spss()`   | NA   |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e863a46b-ca70-4ee5-867a-250416c7f3f9",
   "metadata": {},
   "source": [
    "In diesem Kapitel werden Daten aus dem VDEM-Datensatz (Varieties of Democracy) verwendet. VDEM ist ein laufendes Forschungsprojekt zur Messung des Niveaus der Demokratie in Regierungen auf der ganzen Welt, und es werden laufend aktualisierte Versionen des Datensatzes veröffentlicht. Die Forschung wird von einem Team aus mehr als 50 Sozialwissenschaftlern geleitet, die die Sammlung und Analyse von Experteneinschätzungen von mehr als 3200 Historikern und Länderexperten koordinieren. Auf der Grundlage dieser Einschätzungen hat das VDEM-Projekt eine bemerkenswert komplexe Reihe von Indikatoren entwickelt, die sich an fünf übergeordneten Facetten der Demokratie orientieren: Wahldemokratie, liberale Demokratie, partizipative Demokratie, deliberative Demokratie und egalitäre Demokratie. Der Datensatz reicht bis ins Jahr 1789 zurück und gilt als Goldstandard für quantitative Daten über globale demokratische Entwicklungen.  \n",
    "\n",
    "Das Codebuch finden Sie hier: https://v-dem.net/documents/24/codebook_v13.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "06502fab-a5e8-444f-9f84-8fea3d5690b0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mSignature:\u001b[0m\n",
       "\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'FilePath | ReadCsvBuffer[bytes] | ReadCsvBuffer[str]'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;34m*\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0msep\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'str | None | lib.NoDefault'\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m<\u001b[0m\u001b[0mno_default\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mdelimiter\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'str | None | lib.NoDefault'\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mheader\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"int | Sequence[int] | None | Literal['infer']\"\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'infer'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mnames\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'Sequence[Hashable] | None | lib.NoDefault'\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m<\u001b[0m\u001b[0mno_default\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mindex_col\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'IndexLabel | Literal[False] | None'\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0musecols\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'UsecolsArgType'\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mdtype\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'DtypeArg | None'\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mengine\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'CSVEngine | None'\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mconverters\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'Mapping[Hashable, Callable] | None'\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mtrue_values\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'list | None'\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mfalse_values\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'list | None'\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mskipinitialspace\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'bool'\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mskiprows\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'list[int] | int | Callable[[Hashable], bool] | None'\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mskipfooter\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'int'\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mnrows\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'int | None'\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mna_values\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'Hashable | Iterable[Hashable] | Mapping[Hashable, Iterable[Hashable]] | None'\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mkeep_default_na\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'bool'\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mna_filter\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'bool'\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mverbose\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'bool | lib.NoDefault'\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m<\u001b[0m\u001b[0mno_default\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mskip_blank_lines\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'bool'\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mparse_dates\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'bool | Sequence[Hashable] | None'\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0minfer_datetime_format\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'bool | lib.NoDefault'\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m<\u001b[0m\u001b[0mno_default\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mkeep_date_col\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'bool | lib.NoDefault'\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m<\u001b[0m\u001b[0mno_default\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mdate_parser\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'Callable | lib.NoDefault'\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m<\u001b[0m\u001b[0mno_default\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mdate_format\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'str | dict[Hashable, str] | None'\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mdayfirst\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'bool'\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mcache_dates\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'bool'\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'bool'\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mchunksize\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'int | None'\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mcompression\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'CompressionOptions'\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'infer'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mthousands\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'str | None'\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mdecimal\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'str'\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'.'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mlineterminator\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'str | None'\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mquotechar\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'str'\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'\"'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mquoting\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'int'\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mdoublequote\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'bool'\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mescapechar\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'str | None'\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mcomment\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'str | None'\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mencoding\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'str | None'\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mencoding_errors\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'str | None'\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'strict'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mdialect\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'str | csv.Dialect | None'\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mon_bad_lines\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'str'\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'error'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mdelim_whitespace\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'bool | lib.NoDefault'\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m<\u001b[0m\u001b[0mno_default\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mlow_memory\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'bool'\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mmemory_map\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'bool'\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mfloat_precision\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"Literal['high', 'legacy'] | None\"\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mstorage_options\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'StorageOptions | None'\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mdtype_backend\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'DtypeBackend | lib.NoDefault'\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m<\u001b[0m\u001b[0mno_default\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;34m'DataFrame | TextFileReader'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m\n",
       "Read a comma-separated values (csv) file into DataFrame.\n",
       "\n",
       "Also supports optionally iterating or breaking of the file\n",
       "into chunks.\n",
       "\n",
       "Additional help can be found in the online docs for\n",
       "`IO Tools <https://pandas.pydata.org/pandas-docs/stable/user_guide/io.html>`_.\n",
       "\n",
       "Parameters\n",
       "----------\n",
       "filepath_or_buffer : str, path object or file-like object\n",
       "    Any valid string path is acceptable. The string could be a URL. Valid\n",
       "    URL schemes include http, ftp, s3, gs, and file. For file URLs, a host is\n",
       "    expected. A local file could be: file://localhost/path/to/table.csv.\n",
       "\n",
       "    If you want to pass in a path object, pandas accepts any ``os.PathLike``.\n",
       "\n",
       "    By file-like object, we refer to objects with a ``read()`` method, such as\n",
       "    a file handle (e.g. via builtin ``open`` function) or ``StringIO``.\n",
       "sep : str, default ','\n",
       "    Character or regex pattern to treat as the delimiter. If ``sep=None``, the\n",
       "    C engine cannot automatically detect\n",
       "    the separator, but the Python parsing engine can, meaning the latter will\n",
       "    be used and automatically detect the separator from only the first valid\n",
       "    row of the file by Python's builtin sniffer tool, ``csv.Sniffer``.\n",
       "    In addition, separators longer than 1 character and different from\n",
       "    ``'\\s+'`` will be interpreted as regular expressions and will also force\n",
       "    the use of the Python parsing engine. Note that regex delimiters are prone\n",
       "    to ignoring quoted data. Regex example: ``'\\r\\t'``.\n",
       "delimiter : str, optional\n",
       "    Alias for ``sep``.\n",
       "header : int, Sequence of int, 'infer' or None, default 'infer'\n",
       "    Row number(s) containing column labels and marking the start of the\n",
       "    data (zero-indexed). Default behavior is to infer the column names: if no ``names``\n",
       "    are passed the behavior is identical to ``header=0`` and column\n",
       "    names are inferred from the first line of the file, if column\n",
       "    names are passed explicitly to ``names`` then the behavior is identical to\n",
       "    ``header=None``. Explicitly pass ``header=0`` to be able to\n",
       "    replace existing names. The header can be a list of integers that\n",
       "    specify row locations for a :class:`~pandas.MultiIndex` on the columns\n",
       "    e.g. ``[0, 1, 3]``. Intervening rows that are not specified will be\n",
       "    skipped (e.g. 2 in this example is skipped). Note that this\n",
       "    parameter ignores commented lines and empty lines if\n",
       "    ``skip_blank_lines=True``, so ``header=0`` denotes the first line of\n",
       "    data rather than the first line of the file.\n",
       "names : Sequence of Hashable, optional\n",
       "    Sequence of column labels to apply. If the file contains a header row,\n",
       "    then you should explicitly pass ``header=0`` to override the column names.\n",
       "    Duplicates in this list are not allowed.\n",
       "index_col : Hashable, Sequence of Hashable or False, optional\n",
       "  Column(s) to use as row label(s), denoted either by column labels or column\n",
       "  indices.  If a sequence of labels or indices is given, :class:`~pandas.MultiIndex`\n",
       "  will be formed for the row labels.\n",
       "\n",
       "  Note: ``index_col=False`` can be used to force pandas to *not* use the first\n",
       "  column as the index, e.g., when you have a malformed file with delimiters at\n",
       "  the end of each line.\n",
       "usecols : Sequence of Hashable or Callable, optional\n",
       "    Subset of columns to select, denoted either by column labels or column indices.\n",
       "    If list-like, all elements must either\n",
       "    be positional (i.e. integer indices into the document columns) or strings\n",
       "    that correspond to column names provided either by the user in ``names`` or\n",
       "    inferred from the document header row(s). If ``names`` are given, the document\n",
       "    header row(s) are not taken into account. For example, a valid list-like\n",
       "    ``usecols`` parameter would be ``[0, 1, 2]`` or ``['foo', 'bar', 'baz']``.\n",
       "    Element order is ignored, so ``usecols=[0, 1]`` is the same as ``[1, 0]``.\n",
       "    To instantiate a :class:`~pandas.DataFrame` from ``data`` with element order\n",
       "    preserved use ``pd.read_csv(data, usecols=['foo', 'bar'])[['foo', 'bar']]``\n",
       "    for columns in ``['foo', 'bar']`` order or\n",
       "    ``pd.read_csv(data, usecols=['foo', 'bar'])[['bar', 'foo']]``\n",
       "    for ``['bar', 'foo']`` order.\n",
       "\n",
       "    If callable, the callable function will be evaluated against the column\n",
       "    names, returning names where the callable function evaluates to ``True``. An\n",
       "    example of a valid callable argument would be ``lambda x: x.upper() in\n",
       "    ['AAA', 'BBB', 'DDD']``. Using this parameter results in much faster\n",
       "    parsing time and lower memory usage.\n",
       "dtype : dtype or dict of {Hashable : dtype}, optional\n",
       "    Data type(s) to apply to either the whole dataset or individual columns.\n",
       "    E.g., ``{'a': np.float64, 'b': np.int32, 'c': 'Int64'}``\n",
       "    Use ``str`` or ``object`` together with suitable ``na_values`` settings\n",
       "    to preserve and not interpret ``dtype``.\n",
       "    If ``converters`` are specified, they will be applied INSTEAD\n",
       "    of ``dtype`` conversion.\n",
       "\n",
       "    .. versionadded:: 1.5.0\n",
       "\n",
       "        Support for ``defaultdict`` was added. Specify a ``defaultdict`` as input where\n",
       "        the default determines the ``dtype`` of the columns which are not explicitly\n",
       "        listed.\n",
       "engine : {'c', 'python', 'pyarrow'}, optional\n",
       "    Parser engine to use. The C and pyarrow engines are faster, while the python engine\n",
       "    is currently more feature-complete. Multithreading is currently only supported by\n",
       "    the pyarrow engine.\n",
       "\n",
       "    .. versionadded:: 1.4.0\n",
       "\n",
       "        The 'pyarrow' engine was added as an *experimental* engine, and some features\n",
       "        are unsupported, or may not work correctly, with this engine.\n",
       "converters : dict of {Hashable : Callable}, optional\n",
       "    Functions for converting values in specified columns. Keys can either\n",
       "    be column labels or column indices.\n",
       "true_values : list, optional\n",
       "    Values to consider as ``True`` in addition to case-insensitive variants of 'True'.\n",
       "false_values : list, optional\n",
       "    Values to consider as ``False`` in addition to case-insensitive variants of 'False'.\n",
       "skipinitialspace : bool, default False\n",
       "    Skip spaces after delimiter.\n",
       "skiprows : int, list of int or Callable, optional\n",
       "    Line numbers to skip (0-indexed) or number of lines to skip (``int``)\n",
       "    at the start of the file.\n",
       "\n",
       "    If callable, the callable function will be evaluated against the row\n",
       "    indices, returning ``True`` if the row should be skipped and ``False`` otherwise.\n",
       "    An example of a valid callable argument would be ``lambda x: x in [0, 2]``.\n",
       "skipfooter : int, default 0\n",
       "    Number of lines at bottom of file to skip (Unsupported with ``engine='c'``).\n",
       "nrows : int, optional\n",
       "    Number of rows of file to read. Useful for reading pieces of large files.\n",
       "na_values : Hashable, Iterable of Hashable or dict of {Hashable : Iterable}, optional\n",
       "    Additional strings to recognize as ``NA``/``NaN``. If ``dict`` passed, specific\n",
       "    per-column ``NA`` values.  By default the following values are interpreted as\n",
       "    ``NaN``: \" \", \"#N/A\", \"#N/A N/A\", \"#NA\", \"-1.#IND\", \"-1.#QNAN\", \"-NaN\", \"-nan\",\n",
       "    \"1.#IND\", \"1.#QNAN\", \"<NA>\", \"N/A\", \"NA\", \"NULL\", \"NaN\", \"None\",\n",
       "    \"n/a\", \"nan\", \"null \".\n",
       "\n",
       "keep_default_na : bool, default True\n",
       "    Whether or not to include the default ``NaN`` values when parsing the data.\n",
       "    Depending on whether ``na_values`` is passed in, the behavior is as follows:\n",
       "\n",
       "    * If ``keep_default_na`` is ``True``, and ``na_values`` are specified, ``na_values``\n",
       "      is appended to the default ``NaN`` values used for parsing.\n",
       "    * If ``keep_default_na`` is ``True``, and ``na_values`` are not specified, only\n",
       "      the default ``NaN`` values are used for parsing.\n",
       "    * If ``keep_default_na`` is ``False``, and ``na_values`` are specified, only\n",
       "      the ``NaN`` values specified ``na_values`` are used for parsing.\n",
       "    * If ``keep_default_na`` is ``False``, and ``na_values`` are not specified, no\n",
       "      strings will be parsed as ``NaN``.\n",
       "\n",
       "    Note that if ``na_filter`` is passed in as ``False``, the ``keep_default_na`` and\n",
       "    ``na_values`` parameters will be ignored.\n",
       "na_filter : bool, default True\n",
       "    Detect missing value markers (empty strings and the value of ``na_values``). In\n",
       "    data without any ``NA`` values, passing ``na_filter=False`` can improve the\n",
       "    performance of reading a large file.\n",
       "verbose : bool, default False\n",
       "    Indicate number of ``NA`` values placed in non-numeric columns.\n",
       "\n",
       "    .. deprecated:: 2.2.0\n",
       "skip_blank_lines : bool, default True\n",
       "    If ``True``, skip over blank lines rather than interpreting as ``NaN`` values.\n",
       "parse_dates : bool, list of Hashable, list of lists or dict of {Hashable : list}, default False\n",
       "    The behavior is as follows:\n",
       "\n",
       "    * ``bool``. If ``True`` -> try parsing the index. Note: Automatically set to\n",
       "      ``True`` if ``date_format`` or ``date_parser`` arguments have been passed.\n",
       "    * ``list`` of ``int`` or names. e.g. If ``[1, 2, 3]`` -> try parsing columns 1, 2, 3\n",
       "      each as a separate date column.\n",
       "    * ``list`` of ``list``. e.g.  If ``[[1, 3]]`` -> combine columns 1 and 3 and parse\n",
       "      as a single date column. Values are joined with a space before parsing.\n",
       "    * ``dict``, e.g. ``{'foo' : [1, 3]}`` -> parse columns 1, 3 as date and call\n",
       "      result 'foo'. Values are joined with a space before parsing.\n",
       "\n",
       "    If a column or index cannot be represented as an array of ``datetime``,\n",
       "    say because of an unparsable value or a mixture of timezones, the column\n",
       "    or index will be returned unaltered as an ``object`` data type. For\n",
       "    non-standard ``datetime`` parsing, use :func:`~pandas.to_datetime` after\n",
       "    :func:`~pandas.read_csv`.\n",
       "\n",
       "    Note: A fast-path exists for iso8601-formatted dates.\n",
       "infer_datetime_format : bool, default False\n",
       "    If ``True`` and ``parse_dates`` is enabled, pandas will attempt to infer the\n",
       "    format of the ``datetime`` strings in the columns, and if it can be inferred,\n",
       "    switch to a faster method of parsing them. In some cases this can increase\n",
       "    the parsing speed by 5-10x.\n",
       "\n",
       "    .. deprecated:: 2.0.0\n",
       "        A strict version of this argument is now the default, passing it has no effect.\n",
       "\n",
       "keep_date_col : bool, default False\n",
       "    If ``True`` and ``parse_dates`` specifies combining multiple columns then\n",
       "    keep the original columns.\n",
       "date_parser : Callable, optional\n",
       "    Function to use for converting a sequence of string columns to an array of\n",
       "    ``datetime`` instances. The default uses ``dateutil.parser.parser`` to do the\n",
       "    conversion. pandas will try to call ``date_parser`` in three different ways,\n",
       "    advancing to the next if an exception occurs: 1) Pass one or more arrays\n",
       "    (as defined by ``parse_dates``) as arguments; 2) concatenate (row-wise) the\n",
       "    string values from the columns defined by ``parse_dates`` into a single array\n",
       "    and pass that; and 3) call ``date_parser`` once for each row using one or\n",
       "    more strings (corresponding to the columns defined by ``parse_dates``) as\n",
       "    arguments.\n",
       "\n",
       "    .. deprecated:: 2.0.0\n",
       "       Use ``date_format`` instead, or read in as ``object`` and then apply\n",
       "       :func:`~pandas.to_datetime` as-needed.\n",
       "date_format : str or dict of column -> format, optional\n",
       "    Format to use for parsing dates when used in conjunction with ``parse_dates``.\n",
       "    The strftime to parse time, e.g. :const:`\"%d/%m/%Y\"`. See\n",
       "    `strftime documentation\n",
       "    <https://docs.python.org/3/library/datetime.html\n",
       "    #strftime-and-strptime-behavior>`_ for more information on choices, though\n",
       "    note that :const:`\"%f\"` will parse all the way up to nanoseconds.\n",
       "    You can also pass:\n",
       "\n",
       "    - \"ISO8601\", to parse any `ISO8601 <https://en.wikipedia.org/wiki/ISO_8601>`_\n",
       "        time string (not necessarily in exactly the same format);\n",
       "    - \"mixed\", to infer the format for each element individually. This is risky,\n",
       "        and you should probably use it along with `dayfirst`.\n",
       "\n",
       "    .. versionadded:: 2.0.0\n",
       "dayfirst : bool, default False\n",
       "    DD/MM format dates, international and European format.\n",
       "cache_dates : bool, default True\n",
       "    If ``True``, use a cache of unique, converted dates to apply the ``datetime``\n",
       "    conversion. May produce significant speed-up when parsing duplicate\n",
       "    date strings, especially ones with timezone offsets.\n",
       "\n",
       "iterator : bool, default False\n",
       "    Return ``TextFileReader`` object for iteration or getting chunks with\n",
       "    ``get_chunk()``.\n",
       "chunksize : int, optional\n",
       "    Number of lines to read from the file per chunk. Passing a value will cause the\n",
       "    function to return a ``TextFileReader`` object for iteration.\n",
       "    See the `IO Tools docs\n",
       "    <https://pandas.pydata.org/pandas-docs/stable/io.html#io-chunking>`_\n",
       "    for more information on ``iterator`` and ``chunksize``.\n",
       "\n",
       "compression : str or dict, default 'infer'\n",
       "    For on-the-fly decompression of on-disk data. If 'infer' and 'filepath_or_buffer' is\n",
       "    path-like, then detect compression from the following extensions: '.gz',\n",
       "    '.bz2', '.zip', '.xz', '.zst', '.tar', '.tar.gz', '.tar.xz' or '.tar.bz2'\n",
       "    (otherwise no compression).\n",
       "    If using 'zip' or 'tar', the ZIP file must contain only one data file to be read in.\n",
       "    Set to ``None`` for no decompression.\n",
       "    Can also be a dict with key ``'method'`` set\n",
       "    to one of {``'zip'``, ``'gzip'``, ``'bz2'``, ``'zstd'``, ``'xz'``, ``'tar'``} and\n",
       "    other key-value pairs are forwarded to\n",
       "    ``zipfile.ZipFile``, ``gzip.GzipFile``,\n",
       "    ``bz2.BZ2File``, ``zstandard.ZstdDecompressor``, ``lzma.LZMAFile`` or\n",
       "    ``tarfile.TarFile``, respectively.\n",
       "    As an example, the following could be passed for Zstandard decompression using a\n",
       "    custom compression dictionary:\n",
       "    ``compression={'method': 'zstd', 'dict_data': my_compression_dict}``.\n",
       "\n",
       "    .. versionadded:: 1.5.0\n",
       "        Added support for `.tar` files.\n",
       "\n",
       "    .. versionchanged:: 1.4.0 Zstandard support.\n",
       "\n",
       "thousands : str (length 1), optional\n",
       "    Character acting as the thousands separator in numerical values.\n",
       "decimal : str (length 1), default '.'\n",
       "    Character to recognize as decimal point (e.g., use ',' for European data).\n",
       "lineterminator : str (length 1), optional\n",
       "    Character used to denote a line break. Only valid with C parser.\n",
       "quotechar : str (length 1), optional\n",
       "    Character used to denote the start and end of a quoted item. Quoted\n",
       "    items can include the ``delimiter`` and it will be ignored.\n",
       "quoting : {0 or csv.QUOTE_MINIMAL, 1 or csv.QUOTE_ALL, 2 or csv.QUOTE_NONNUMERIC, 3 or csv.QUOTE_NONE}, default csv.QUOTE_MINIMAL\n",
       "    Control field quoting behavior per ``csv.QUOTE_*`` constants. Default is\n",
       "    ``csv.QUOTE_MINIMAL`` (i.e., 0) which implies that only fields containing special\n",
       "    characters are quoted (e.g., characters defined in ``quotechar``, ``delimiter``,\n",
       "    or ``lineterminator``.\n",
       "doublequote : bool, default True\n",
       "   When ``quotechar`` is specified and ``quoting`` is not ``QUOTE_NONE``, indicate\n",
       "   whether or not to interpret two consecutive ``quotechar`` elements INSIDE a\n",
       "   field as a single ``quotechar`` element.\n",
       "escapechar : str (length 1), optional\n",
       "    Character used to escape other characters.\n",
       "comment : str (length 1), optional\n",
       "    Character indicating that the remainder of line should not be parsed.\n",
       "    If found at the beginning\n",
       "    of a line, the line will be ignored altogether. This parameter must be a\n",
       "    single character. Like empty lines (as long as ``skip_blank_lines=True``),\n",
       "    fully commented lines are ignored by the parameter ``header`` but not by\n",
       "    ``skiprows``. For example, if ``comment='#'``, parsing\n",
       "    ``#empty\\na,b,c\\n1,2,3`` with ``header=0`` will result in ``'a,b,c'`` being\n",
       "    treated as the header.\n",
       "encoding : str, optional, default 'utf-8'\n",
       "    Encoding to use for UTF when reading/writing (ex. ``'utf-8'``). `List of Python\n",
       "    standard encodings\n",
       "    <https://docs.python.org/3/library/codecs.html#standard-encodings>`_ .\n",
       "\n",
       "encoding_errors : str, optional, default 'strict'\n",
       "    How encoding errors are treated. `List of possible values\n",
       "    <https://docs.python.org/3/library/codecs.html#error-handlers>`_ .\n",
       "\n",
       "    .. versionadded:: 1.3.0\n",
       "\n",
       "dialect : str or csv.Dialect, optional\n",
       "    If provided, this parameter will override values (default or not) for the\n",
       "    following parameters: ``delimiter``, ``doublequote``, ``escapechar``,\n",
       "    ``skipinitialspace``, ``quotechar``, and ``quoting``. If it is necessary to\n",
       "    override values, a ``ParserWarning`` will be issued. See ``csv.Dialect``\n",
       "    documentation for more details.\n",
       "on_bad_lines : {'error', 'warn', 'skip'} or Callable, default 'error'\n",
       "    Specifies what to do upon encountering a bad line (a line with too many fields).\n",
       "    Allowed values are :\n",
       "\n",
       "    - ``'error'``, raise an Exception when a bad line is encountered.\n",
       "    - ``'warn'``, raise a warning when a bad line is encountered and skip that line.\n",
       "    - ``'skip'``, skip bad lines without raising or warning when they are encountered.\n",
       "\n",
       "    .. versionadded:: 1.3.0\n",
       "\n",
       "    .. versionadded:: 1.4.0\n",
       "\n",
       "        - Callable, function with signature\n",
       "          ``(bad_line: list[str]) -> list[str] | None`` that will process a single\n",
       "          bad line. ``bad_line`` is a list of strings split by the ``sep``.\n",
       "          If the function returns ``None``, the bad line will be ignored.\n",
       "          If the function returns a new ``list`` of strings with more elements than\n",
       "          expected, a ``ParserWarning`` will be emitted while dropping extra elements.\n",
       "          Only supported when ``engine='python'``\n",
       "\n",
       "    .. versionchanged:: 2.2.0\n",
       "\n",
       "        - Callable, function with signature\n",
       "          as described in `pyarrow documentation\n",
       "          <https://arrow.apache.org/docs/python/generated/pyarrow.csv.ParseOptions.html\n",
       "          #pyarrow.csv.ParseOptions.invalid_row_handler>`_ when ``engine='pyarrow'``\n",
       "\n",
       "delim_whitespace : bool, default False\n",
       "    Specifies whether or not whitespace (e.g. ``' '`` or ``'\\t'``) will be\n",
       "    used as the ``sep`` delimiter. Equivalent to setting ``sep='\\s+'``. If this option\n",
       "    is set to ``True``, nothing should be passed in for the ``delimiter``\n",
       "    parameter.\n",
       "\n",
       "    .. deprecated:: 2.2.0\n",
       "        Use ``sep=\"\\s+\"`` instead.\n",
       "low_memory : bool, default True\n",
       "    Internally process the file in chunks, resulting in lower memory use\n",
       "    while parsing, but possibly mixed type inference.  To ensure no mixed\n",
       "    types either set ``False``, or specify the type with the ``dtype`` parameter.\n",
       "    Note that the entire file is read into a single :class:`~pandas.DataFrame`\n",
       "    regardless, use the ``chunksize`` or ``iterator`` parameter to return the data in\n",
       "    chunks. (Only valid with C parser).\n",
       "memory_map : bool, default False\n",
       "    If a filepath is provided for ``filepath_or_buffer``, map the file object\n",
       "    directly onto memory and access the data directly from there. Using this\n",
       "    option can improve performance because there is no longer any I/O overhead.\n",
       "float_precision : {'high', 'legacy', 'round_trip'}, optional\n",
       "    Specifies which converter the C engine should use for floating-point\n",
       "    values. The options are ``None`` or ``'high'`` for the ordinary converter,\n",
       "    ``'legacy'`` for the original lower precision pandas converter, and\n",
       "    ``'round_trip'`` for the round-trip converter.\n",
       "\n",
       "storage_options : dict, optional\n",
       "    Extra options that make sense for a particular storage connection, e.g.\n",
       "    host, port, username, password, etc. For HTTP(S) URLs the key-value pairs\n",
       "    are forwarded to ``urllib.request.Request`` as header options. For other\n",
       "    URLs (e.g. starting with \"s3://\", and \"gcs://\") the key-value pairs are\n",
       "    forwarded to ``fsspec.open``. Please see ``fsspec`` and ``urllib`` for more\n",
       "    details, and for more examples on storage options refer `here\n",
       "    <https://pandas.pydata.org/docs/user_guide/io.html?\n",
       "    highlight=storage_options#reading-writing-remote-files>`_.\n",
       "\n",
       "dtype_backend : {'numpy_nullable', 'pyarrow'}, default 'numpy_nullable'\n",
       "    Back-end data type applied to the resultant :class:`DataFrame`\n",
       "    (still experimental). Behaviour is as follows:\n",
       "\n",
       "    * ``\"numpy_nullable\"``: returns nullable-dtype-backed :class:`DataFrame`\n",
       "      (default).\n",
       "    * ``\"pyarrow\"``: returns pyarrow-backed nullable :class:`ArrowDtype`\n",
       "      DataFrame.\n",
       "\n",
       "    .. versionadded:: 2.0\n",
       "\n",
       "Returns\n",
       "-------\n",
       "DataFrame or TextFileReader\n",
       "    A comma-separated values (csv) file is returned as two-dimensional\n",
       "    data structure with labeled axes.\n",
       "\n",
       "See Also\n",
       "--------\n",
       "DataFrame.to_csv : Write DataFrame to a comma-separated values (csv) file.\n",
       "read_table : Read general delimited file into DataFrame.\n",
       "read_fwf : Read a table of fixed-width formatted lines into DataFrame.\n",
       "\n",
       "Examples\n",
       "--------\n",
       ">>> pd.read_csv('data.csv')  # doctest: +SKIP\n",
       "\u001b[0;31mFile:\u001b[0m      ~/anaconda3/envs/python_course/lib/python3.9/site-packages/pandas/io/parsers/readers.py\n",
       "\u001b[0;31mType:\u001b[0m      function"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.read_csv?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "a6d2c349-849c-4de9-b450-9f51df0886db",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/vdem/V-Dem-CY-Full+Others-v10.csv',\n",
    "                low_memory=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a34513fb-f73d-4d63-83a7-59bb2d330418",
   "metadata": {},
   "source": [
    "Wie viele Zeilen und Spalten? Das geht mit der `.shape` Methode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "1453c9d8-6c6a-4de3-86fc-6202ad29d28b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(27013, 48)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "375438d1-55b7-495a-8421-383c4ec4e39f",
   "metadata": {},
   "source": [
    "Welche Variablen benötigen wir? Wir wählen Spalten in einem DataFrame aus, indem wir den DataFrame aufrufen gefolt mit einer Liste in eckigen Klammern, die die Namen der Spalten enthält."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4be09ba-5077-42be-8a66-3b370d25d800",
   "metadata": {},
   "source": [
    "Wir können die Namen der Spalten (columns) mithilfe des Attributs `.columns` für den DataFrame ausdrucken:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "e683712a-6a83-4bd9-a1ae-f6dbd82a86cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['country_name',\n",
       " 'country_text_id',\n",
       " 'e_regiongeo',\n",
       " 'year',\n",
       " 'v2x_polyarchy',\n",
       " 'v2x_libdem',\n",
       " 'v2x_partipdem',\n",
       " 'v2x_delibdem',\n",
       " 'v2x_egaldem',\n",
       " 'v2smprivex',\n",
       " 'v2smpolsoc',\n",
       " 'v2caviol',\n",
       " 'e_boix_regime',\n",
       " 'v2dlreason',\n",
       " 'v2dlcommon',\n",
       " 'v2dlcountr',\n",
       " 'v2dlconslt',\n",
       " 'v2dlengage',\n",
       " 'v2dlencmps',\n",
       " 'v2dlunivl',\n",
       " 'v2cseeorgs',\n",
       " 'v2csreprss',\n",
       " 'v2cscnsult',\n",
       " 'v2csprtcpt',\n",
       " 'v2csgender',\n",
       " 'v2csantimv',\n",
       " 'v2csrlgrep',\n",
       " 'v2csrlgcon',\n",
       " 'v2mecenefm',\n",
       " 'v2mecenefi',\n",
       " 'v2mecenefibin',\n",
       " 'v2mecrit',\n",
       " 'v2merange',\n",
       " 'v2mefemjrn',\n",
       " 'v2meharjrn',\n",
       " 'v2meslfcen',\n",
       " 'v2mebias',\n",
       " 'v2mecorrpt',\n",
       " 'v2exrescon',\n",
       " 'v2exbribe',\n",
       " 'v2exembez',\n",
       " 'v2excrptps',\n",
       " 'v2exthftps',\n",
       " 'v2cldiscm',\n",
       " 'v2cldiscw',\n",
       " 'v2clacfree',\n",
       " 'v2clrelig',\n",
       " 'v2clfmove']"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9431dd3b-b1fc-4b93-94b2-a325e82f763f",
   "metadata": {},
   "source": [
    "In diesem Fall möchten wir die folgenden Variablen behalten: \n",
    "\n",
    "1. den Ländernamen \n",
    "2. die Länder-ID \n",
    "3. die geografische Region \n",
    "4. Die Länder-ID \n",
    "3. die geographische Region \n",
    "4. Das Jahr 5. Der Polyarchie-Index \n",
    "6. Der Index der liberalen Demokratie\n",
    "7. Der Index der partizipativen Demokratie \n",
    "8. Der Index der deliberativen Demokratie \n",
    "9. Der Index der egalitären Demokratie \n",
    "10. Ob die Privatsphäre der Internetnutzer und ihre Daten rechtlich geschützt sind \n",
    "11. Wie polarisiert das Land in politischen Fragen ist \n",
    "12. Ausmaß der politischen Gewalt \n",
    "13. Ob das Land eine Demokratie ist oder nicht \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "f531eed1-ca07-478c-8480-99e060d9de09",
   "metadata": {},
   "outputs": [],
   "source": [
    "subset_vars = ['country_name', 'country_text_id', 'e_regiongeo', \n",
    "               'year', 'v2x_polyarchy', 'v2x_libdem', 'v2x_partipdem', \n",
    "               'v2x_delibdem', 'v2x_egaldem', 'v2smprivex', 'v2smpolsoc', \n",
    "               'v2caviol', 'e_boix_regime']\n",
    "\n",
    "sdf = df[subset_vars]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "f22650fd-08d5-4b77-b3d8-5b2410c6ae8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(27013, 13)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sdf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "46665d88-57be-4e00-9d8e-e45f6678c175",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['country_name',\n",
       " 'country_text_id',\n",
       " 'e_regiongeo',\n",
       " 'year',\n",
       " 'v2x_polyarchy',\n",
       " 'v2x_libdem',\n",
       " 'v2x_partipdem',\n",
       " 'v2x_delibdem',\n",
       " 'v2x_egaldem',\n",
       " 'v2smprivex',\n",
       " 'v2smpolsoc',\n",
       " 'v2caviol',\n",
       " 'e_boix_regime']"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(sdf.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb99c474-a749-46ee-993f-f51418c8f68c",
   "metadata": {},
   "source": [
    "### Was ist im DataFrame?\n",
    "\n",
    "Mit der Methode `.info()` können wir die Gesamtzahl der Beobachtungen, die Gesamtzahl der Spalten, die Namen der Spalten, die Anzahl der nicht fehlenden Beobachtungen für jede Variable, den Datentyp für jede Variable, die Anzahl der Variablen, die Daten jedes Typs enthalten (z. B. Ganzzahlen und Fließkommazahlen), und die Gesamtmenge des vom DataFrame verwendeten Speichers anzeigen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "8f03981e-3079-4985-a9b6-929373f9daf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 27013 entries, 0 to 27012\n",
      "Data columns (total 13 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   country_name     27013 non-null  object \n",
      " 1   country_text_id  27013 non-null  object \n",
      " 2   e_regiongeo      27013 non-null  int64  \n",
      " 3   year             27013 non-null  int64  \n",
      " 4   v2x_polyarchy    25342 non-null  float64\n",
      " 5   v2x_libdem       24350 non-null  float64\n",
      " 6   v2x_partipdem    24923 non-null  float64\n",
      " 7   v2x_delibdem     18557 non-null  float64\n",
      " 8   v2x_egaldem      18557 non-null  float64\n",
      " 9   v2smprivex       3562 non-null   float64\n",
      " 10  v2smpolsoc       3562 non-null   float64\n",
      " 11  v2caviol         12745 non-null  float64\n",
      " 12  e_boix_regime    16270 non-null  float64\n",
      "dtypes: float64(9), int64(2), object(2)\n",
      "memory usage: 2.7+ MB\n"
     ]
    }
   ],
   "source": [
    "sdf.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fcfbf4b-72c9-4cc1-8031-13419052cae6",
   "metadata": {},
   "source": [
    "Die Datentypen in diesem Datenrahmen sind float64 (Zahlen mit Nachkommastellen), int64 (Ganzzahlen) und object. In Pandas bezieht sich object auf Spalten, die Strings oder gemischte Typen wie Strings und Integers enthalten (object umfasst auch viele andere Dinge: es ist eine Sammelkategorie). Pandas kann auch mit Booleans (Wahr oder Falsch), kategorischen Variablen und einigen speziellen Datetime-Objekten arbeiten. Erinnern Sie sich daran, wie wir die Spalten für unser Dataset ausgewählt haben. Im folgenden Code verwende ich dieselbe Idee, um nur einige wenige Variablen anzuzeigen. Wir werden dies später in diesem Kapitel noch etwas genauer erklären."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "115ca60a-a2a7-45fe-9480-3f388ce084d7",
   "metadata": {},
   "source": [
    "Wir können auch die Methode `.describe()` verwenden, um zusammenfassende Informationen über die quantitativen Variablen in unserem Datensatz zu erhalten, einschließlich der Anzahl der nicht fehlenden Informationen, des Mittelwerts und der Standardabweichung.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "e53107fc-34e6-49fd-91da-870eb03bcecd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>e_regiongeo</th>\n",
       "      <th>year</th>\n",
       "      <th>v2x_polyarchy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>27013.000000</td>\n",
       "      <td>27013.000000</td>\n",
       "      <td>25342.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>9.266575</td>\n",
       "      <td>1926.556177</td>\n",
       "      <td>0.262821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>5.733007</td>\n",
       "      <td>63.754335</td>\n",
       "      <td>0.260966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1789.000000</td>\n",
       "      <td>0.007000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>1878.000000</td>\n",
       "      <td>0.057000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>8.000000</td>\n",
       "      <td>1937.000000</td>\n",
       "      <td>0.171500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>14.000000</td>\n",
       "      <td>1980.000000</td>\n",
       "      <td>0.367000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>19.000000</td>\n",
       "      <td>2019.000000</td>\n",
       "      <td>0.924000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        e_regiongeo          year  v2x_polyarchy\n",
       "count  27013.000000  27013.000000   25342.000000\n",
       "mean       9.266575   1926.556177       0.262821\n",
       "std        5.733007     63.754335       0.260966\n",
       "min        1.000000   1789.000000       0.007000\n",
       "25%        4.000000   1878.000000       0.057000\n",
       "50%        8.000000   1937.000000       0.171500\n",
       "75%       14.000000   1980.000000       0.367000\n",
       "max       19.000000   2019.000000       0.924000"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sdf[['e_regiongeo', 'year', 'v2x_polyarchy']].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69176d08-57e0-46ba-a59e-3382e6eac81b",
   "metadata": {},
   "source": [
    "### Heads, tails, and samples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89fb425a-800f-49f5-9053-4daa6aeed105",
   "metadata": {},
   "source": [
    "Wir können auch den \"Kopf\" oder das \"Ende\" unseres Datenrahmens mit den Methoden `.head() ` und `.tail()` untersuchen, die standardmäßig die ersten oder letzten fünf Zeilen in einem DataFrame verwenden, es sei denn, Sie geben eine andere Zahl als Argument an, wie z. B. `.head(10)`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "ebce73cf-4a18-480c-8998-1e17703a276d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country_name</th>\n",
       "      <th>year</th>\n",
       "      <th>v2x_libdem</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Mexico</td>\n",
       "      <td>1789</td>\n",
       "      <td>0.043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Mexico</td>\n",
       "      <td>1790</td>\n",
       "      <td>0.040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mexico</td>\n",
       "      <td>1791</td>\n",
       "      <td>0.040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Mexico</td>\n",
       "      <td>1792</td>\n",
       "      <td>0.040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Mexico</td>\n",
       "      <td>1793</td>\n",
       "      <td>0.040</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  country_name  year  v2x_libdem\n",
       "0       Mexico  1789       0.043\n",
       "1       Mexico  1790       0.040\n",
       "2       Mexico  1791       0.040\n",
       "3       Mexico  1792       0.040\n",
       "4       Mexico  1793       0.040"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sdf[['country_name', 'year', 'v2x_libdem']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "b3b58c99-a99c-4c56-acf6-34a3d64bab23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country_name</th>\n",
       "      <th>year</th>\n",
       "      <th>v2x_libdem</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>27010</th>\n",
       "      <td>Piedmont-Sardinia</td>\n",
       "      <td>1859</td>\n",
       "      <td>0.150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27011</th>\n",
       "      <td>Piedmont-Sardinia</td>\n",
       "      <td>1860</td>\n",
       "      <td>0.148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27012</th>\n",
       "      <td>Piedmont-Sardinia</td>\n",
       "      <td>1861</td>\n",
       "      <td>0.149</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            country_name  year  v2x_libdem\n",
       "27010  Piedmont-Sardinia  1859       0.150\n",
       "27011  Piedmont-Sardinia  1860       0.148\n",
       "27012  Piedmont-Sardinia  1861       0.149"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sdf[['country_name', 'year', 'v2x_libdem']].tail(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e392366-c98c-4c33-81bc-78efa65f4270",
   "metadata": {},
   "source": [
    "Wenn Sie eine Zufallsstichprobe von Zeilen bevorzugen, können Sie die Methode `.sample()` verwenden, bei der Sie die Anzahl der Zeilen angeben müssen, die Sie abfragen möchten:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "c866c43b-0f6e-4baf-a7e6-d777026f4eb0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country_name</th>\n",
       "      <th>year</th>\n",
       "      <th>v2x_libdem</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>17391</th>\n",
       "      <td>Laos</td>\n",
       "      <td>1911</td>\n",
       "      <td>0.063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14484</th>\n",
       "      <td>Syria</td>\n",
       "      <td>2009</td>\n",
       "      <td>0.050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2471</th>\n",
       "      <td>Poland</td>\n",
       "      <td>1791</td>\n",
       "      <td>0.185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18559</th>\n",
       "      <td>Togo</td>\n",
       "      <td>1927</td>\n",
       "      <td>0.020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17295</th>\n",
       "      <td>Jamaica</td>\n",
       "      <td>1995</td>\n",
       "      <td>0.521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3083</th>\n",
       "      <td>United States of America</td>\n",
       "      <td>2007</td>\n",
       "      <td>0.851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15709</th>\n",
       "      <td>Azerbaijan</td>\n",
       "      <td>2016</td>\n",
       "      <td>0.056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1498</th>\n",
       "      <td>Burma/Myanmar</td>\n",
       "      <td>2014</td>\n",
       "      <td>0.170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24564</th>\n",
       "      <td>Serbia</td>\n",
       "      <td>2010</td>\n",
       "      <td>0.527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11915</th>\n",
       "      <td>Iran</td>\n",
       "      <td>1884</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16753</th>\n",
       "      <td>Eritrea</td>\n",
       "      <td>1953</td>\n",
       "      <td>0.081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9474</th>\n",
       "      <td>Mauritania</td>\n",
       "      <td>1940</td>\n",
       "      <td>0.078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14903</th>\n",
       "      <td>Turkey</td>\n",
       "      <td>1966</td>\n",
       "      <td>0.372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22385</th>\n",
       "      <td>Luxembourg</td>\n",
       "      <td>2016</td>\n",
       "      <td>0.813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7313</th>\n",
       "      <td>Thailand</td>\n",
       "      <td>2002</td>\n",
       "      <td>0.432</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   country_name  year  v2x_libdem\n",
       "17391                      Laos  1911       0.063\n",
       "14484                     Syria  2009       0.050\n",
       "2471                     Poland  1791       0.185\n",
       "18559                      Togo  1927       0.020\n",
       "17295                   Jamaica  1995       0.521\n",
       "3083   United States of America  2007       0.851\n",
       "15709                Azerbaijan  2016       0.056\n",
       "1498              Burma/Myanmar  2014       0.170\n",
       "24564                    Serbia  2010       0.527\n",
       "11915                      Iran  1884         NaN\n",
       "16753                   Eritrea  1953       0.081\n",
       "9474                 Mauritania  1940       0.078\n",
       "14903                    Turkey  1966       0.372\n",
       "22385                Luxembourg  2016       0.813\n",
       "7313                   Thailand  2002       0.432"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sdf[['country_name', 'year', 'v2x_libdem']].sample(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "416db6a2-de43-4f60-869d-27a53bf378be",
   "metadata": {},
   "source": [
    "### Zeilen filtern"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94a8d2ae-d93d-4dda-b58d-6b82ac5e8040",
   "metadata": {},
   "source": [
    "Bei der Ausführung der Methode `.describe()` haben Sie vielleicht bemerkt, dass der Bereich für die Jahresvariable 1789-2019 ist. Angenommen, wir haben einen guten Grund, uns auf die Jahre von 1900 bis 2019 zu konzentrieren. Dann müssen wir die Daten filtern, um nur die Zeilen zu erhalten, die unseren Anforderungen entsprechen. Es gibt mehrere Möglichkeiten, Zeilen zu filtern, einschließlich Slices (z. B. alle Beobachtungen zwischen Index i und Index j) oder nach einer expliziten Bedingung, wie z. B. \"Zeilen, in denen das Jahr >= 1900\". Beachten Sie, dass, wenn wir einen DataFrame filtern oder zerschneiden, das neue Objekt nur eine Ansicht des Originals ist und sich immer noch auf die gleichen Daten bezieht. Pandas warnt uns, wenn wir versuchen, das gefilterte Objekt zu verändern, so dass es in den meisten Fällen einfacher ist, eine neue Kopie zu erstellen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "03f114c9-94c6-468c-bd1b-f63087672d48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 18787 entries, 111 to 25622\n",
      "Data columns (total 13 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   country_name     18787 non-null  object \n",
      " 1   country_text_id  18787 non-null  object \n",
      " 2   e_regiongeo      18787 non-null  int64  \n",
      " 3   year             18787 non-null  int64  \n",
      " 4   v2x_polyarchy    18663 non-null  float64\n",
      " 5   v2x_libdem       18424 non-null  float64\n",
      " 6   v2x_partipdem    18587 non-null  float64\n",
      " 7   v2x_delibdem     18557 non-null  float64\n",
      " 8   v2x_egaldem      18557 non-null  float64\n",
      " 9   v2smprivex       3562 non-null   float64\n",
      " 10  v2smpolsoc       3562 non-null   float64\n",
      " 11  v2caviol         12745 non-null  float64\n",
      " 12  e_boix_regime    11841 non-null  float64\n",
      "dtypes: float64(9), int64(2), object(2)\n",
      "memory usage: 2.0+ MB\n"
     ]
    }
   ],
   "source": [
    "fsdf = sdf[sdf['year'] >= 1900].copy()\n",
    "fsdf.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b736466e-450f-4d27-a87a-e089540432df",
   "metadata": {},
   "source": [
    "### Schreiben von Dateien"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "522d29d1-4ab0-4c10-a9bd-a237b2a8c439",
   "metadata": {},
   "source": [
    "So wie wir unsere ursprüngliche CSV-Datei mit der Funktion `read_csv()` in Pandas eingelesen habe, können wir diesen neuen Dataframe mit der Methode `to_csv()` auch wieder schreiben:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "6e4904a9-6cd4-4a98-a596-40e555b9cedb",
   "metadata": {},
   "outputs": [],
   "source": [
    "fsdf.to_csv('../data/vdem/filtered_subset.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "080de2b6-7bf8-4136-bcf2-19539666c3f6",
   "metadata": {},
   "source": [
    "<div class='alert alert-block alert-success'>\n",
    "\n",
    "### Aufgabe 3\n",
    "\n",
    "--> session_03_excercise_3.ipynb\n",
    "\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:python_course]",
   "language": "python",
   "name": "conda-env-python_course-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
